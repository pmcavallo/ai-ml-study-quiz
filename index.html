<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI/ML Study Quiz</title>
    <script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useEffect } = React;

        // Icon components
        const BookOpen = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <path d="M2 3h6a4 4 0 0 1 4 4v14a3 3 0 0 0-3-3H2z"/>
                <path d="M22 3h-6a4 4 0 0 0-4 4v14a3 3 0 0 1 3-3h7z"/>
            </svg>
        );

        const Brain = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <path d="M9.5 2A2.5 2.5 0 0 1 12 4.5v15a2.5 2.5 0 0 1-4.96.44 2.5 2.5 0 0 1-2.96-3.08 3 3 0 0 1-.34-5.58 2.5 2.5 0 0 1 1.32-4.24 2.5 2.5 0 0 1 1.98-3A2.5 2.5 0 0 1 9.5 2Z"/>
                <path d="M14.5 2A2.5 2.5 0 0 0 12 4.5v15a2.5 2.5 0 0 0 4.96.44 2.5 2.5 0 0 0 2.96-3.08 3 3 0 0 0 .34-5.58 2.5 2.5 0 0 0-1.32-4.24 2.5 2.5 0 0 0-1.98-3A2.5 2.5 0 0 0 14.5 2Z"/>
            </svg>
        );

        const Award = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <circle cx="12" cy="8" r="6"/>
                <path d="M15.477 12.89 17 22l-5-3-5 3 1.523-9.11"/>
            </svg>
        );

        const TrendingUp = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <polyline points="22,7 13.5,15.5 8.5,10.5 2,17"/>
                <polyline points="16,7 22,7 22,13"/>
            </svg>
        );

        const RotateCcw = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <path d="M3 12a9 9 0 1 0 9-9 9.75 9.75 0 0 0-6.74 2.74L3 8"/>
                <path d="M3 3v5h5"/>
            </svg>
        );

        const CheckCircle = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                <polyline points="22,4 12,14.01 9,11.01"/>
            </svg>
        );

        const XCircle = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <circle cx="12" cy="12" r="10"/>
                <path d="M15 9l-6 6"/>
                <path d="M9 9l6 6"/>
            </svg>
        );

        const Lightbulb = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <path d="M15 14c.2-1 .7-1.7 1.5-2.5 1-.9 1.5-2.2 1.5-3.5A6 6 0 0 0 6 8c0 1 .2 2.2 1.5 3.5.7.7 1.3 1.5 1.5 2.5"/>
                <path d="M9 18h6"/>
                <path d="M10 22h4"/>
            </svg>
        );

        const BarChart3 = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <path d="M3 3v18h18"/>
                <path d="M18 17V9"/>
                <path d="M13 17V5"/>
                <path d="M8 17v-3"/>
            </svg>
        );

        const Shuffle = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <polyline points="16,3 21,3 21,8"/>
                <line x1="4" y1="20" x2="21" y2="3"/>
                <polyline points="21,16 21,21 16,21"/>
                <line x1="15" y1="15" x2="21" y2="21"/>
                <line x1="4" y1="4" x2="9" y2="9"/>
            </svg>
        );

        const AIMLQuizApp = () => {
            const [currentTopic, setCurrentTopic] = useState('random');
            const [difficulty, setDifficulty] = useState(1);
            const [currentQuestion, setCurrentQuestion] = useState(null);
            const [userAnswer, setUserAnswer] = useState('');
            const [showAnswer, setShowAnswer] = useState(false);
            const [usedQuestions, setUsedQuestions] = useState(new Set());
            const [streaks, setStreaks] = useState({
                cloud: 0, mlops: 0, modeling: 0, general: 0, python_sql: 0, production: 0, data_eng: 0, ethics: 0
            });
            const [weeklyStats, setWeeklyStats] = useState({
                questionsAnswered: 0,
                correctAnswers: 0,
                topicProgress: {
                    cloud: { correct: 0, total: 0 },
                    mlops: { correct: 0, total: 0 },
                    modeling: { correct: 0, total: 0 },
                    general: { correct: 0, total: 0 },
                    python_sql: { correct: 0, total: 0 },
                    production: { correct: 0, total: 0 },
                    data_eng: { correct: 0, total: 0 },
                    ethics: { correct: 0, total: 0 }
                }
            });
            const [showWeeklyReport, setShowWeeklyReport] = useState(false);

            const topics = {
                cloud: 'Cloud (AWS/GCP)',
                mlops: 'MLOps',
                modeling: 'Modeling & Deployment',
                general: 'AI General Knowledge',
                python_sql: 'Python/SQL Coding',
                production: 'AI in Production',
                data_eng: 'Data Engineering for ML',
                ethics: 'AI Ethics & Fairness',
                random: 'Random Mix'
            };

            const questionBank = {
                cloud: {
                    1: [
                        { q: "What does S3 stand for in AWS?", a: "Simple Storage Service", options: ["Simple Storage Service", "Scalable Storage System", "Secure Storage Solution", "Smart Storage Service"], explanation: "S3 stands for Simple Storage Service, AWS's object storage service designed for scalability, data availability, security, and performance." },
                        { q: "Which GCP service is equivalent to AWS Lambda?", a: "Cloud Functions", options: ["Cloud Functions", "Cloud Run", "App Engine", "Compute Engine"], explanation: "Cloud Functions is Google's serverless compute service, directly equivalent to AWS Lambda for running code without managing servers." },
                        { q: "What is the main purpose of AWS IAM?", a: "Identity and Access Management", options: ["Internet Access Management", "Identity and Access Management", "Infrastructure Asset Management", "Internal Application Monitoring"], explanation: "IAM (Identity and Access Management) controls who can access AWS resources and what they can do with them." },
                        { q: "What does EC2 stand for in AWS?", a: "Elastic Compute Cloud", options: ["Elastic Compute Cloud", "Enhanced Cloud Computing", "Enterprise Computing Center", "Elastic Container Cloud"], explanation: "EC2 (Elastic Compute Cloud) provides resizable compute capacity in the cloud, allowing you to run virtual servers." },
                        { q: "Which AWS service provides managed relational databases?", a: "RDS", options: ["DynamoDB", "RDS", "DocumentDB", "Neptune"], explanation: "RDS (Relational Database Service) makes it easy to set up, operate, and scale relational databases in the cloud." },
                        { q: "What is the default storage class for S3 objects?", a: "Standard", options: ["Standard", "Intelligent-Tiering", "Standard-IA", "Glacier"], explanation: "S3 Standard is the default storage class, providing high durability, availability, and performance for frequently accessed data." },
                        { q: "Which GCP service is used for big data analytics?", a: "BigQuery", options: ["BigQuery", "Cloud SQL", "Firestore", "Cloud Spanner"], explanation: "BigQuery is Google's fully-managed, serverless data warehouse designed for large-scale data analytics." },
                        { q: "What is the AWS equivalent of Google Cloud Storage?", a: "S3", options: ["EBS", "EFS", "S3", "Glacier"], explanation: "S3 (Simple Storage Service) is AWS's object storage service, equivalent to Google Cloud Storage." },
                        { q: "Which AWS service provides content delivery network (CDN)?", a: "CloudFront", options: ["CloudFront", "Route 53", "API Gateway", "CloudWatch"], explanation: "CloudFront is AWS's content delivery network service that delivers data, videos, applications, and APIs globally with low latency." },
                        { q: "What does VPC stand for in cloud computing?", a: "Virtual Private Cloud", options: ["Virtual Private Cloud", "Virtual Public Cloud", "Very Private Computing", "Virtual Processing Center"], explanation: "VPC (Virtual Private Cloud) lets you provision a logically isolated section of the cloud where you can launch resources in a virtual network." },
                        { q: "Which GCP service provides managed Kubernetes?", a: "GKE", options: ["GCE", "GKE", "Cloud Run", "App Engine"], explanation: "GKE (Google Kubernetes Engine) is a managed Kubernetes service that simplifies deploying, managing, and scaling containerized applications." },
                        { q: "What is the purpose of AWS CloudWatch?", a: "Monitoring and logging", options: ["Load balancing", "Monitoring and logging", "Database management", "File storage"], explanation: "CloudWatch is AWS's monitoring and observability service that provides data and actionable insights for applications and infrastructure." },
                        { q: "Which AWS service provides serverless computing?", a: "Lambda", options: ["EC2", "Lambda", "ECS", "Batch"], explanation: "AWS Lambda lets you run code without provisioning or managing servers, charging only for compute time consumed." },
                        { q: "What is the GCP equivalent of AWS EC2?", a: "Compute Engine", options: ["Cloud Functions", "App Engine", "Compute Engine", "Cloud Run"], explanation: "Compute Engine provides virtual machines that run on Google's infrastructure, similar to AWS EC2." },
                        { q: "Which AWS service provides managed NoSQL database?", a: "DynamoDB", options: ["RDS", "DynamoDB", "ElastiCache", "Redshift"], explanation: "DynamoDB is AWS's fully managed NoSQL database service that provides fast and predictable performance with seamless scalability." },
                        { q: "What does auto-scaling do in cloud computing?", a: "Automatically adjusts resource capacity", options: ["Automatically adjusts resource capacity", "Automatically backs up data", "Automatically updates software", "Automatically encrypts data"], explanation: "Auto-scaling automatically adjusts the number of compute resources allocated to your application based on demand." }
                    ],
                    2: [
                        { q: "What is the difference between AWS ECS and EKS?", a: "ECS is AWS container service, EKS is managed Kubernetes", options: ["ECS is AWS container service, EKS is managed Kubernetes", "ECS is for databases, EKS is for storage", "No practical difference", "ECS is newer than EKS"], explanation: "ECS (Elastic Container Service) is AWS's proprietary container orchestration, while EKS (Elastic Kubernetes Service) is AWS's managed Kubernetes offering." },
                        { q: "What is AWS CloudFormation used for?", a: "Infrastructure as Code", options: ["Data analytics", "Infrastructure as Code", "Machine learning", "Content delivery"], explanation: "CloudFormation allows you to define cloud infrastructure using templates, enabling version control and repeatable deployments." },
                        { q: "Which GCP service provides serverless SQL databases?", a: "Cloud SQL", options: ["BigQuery", "Cloud SQL", "Firestore", "Cloud Spanner"], explanation: "Cloud SQL is a fully-managed relational database service for MySQL, PostgreSQL, and SQL Server." },
                        { q: "What is the difference between horizontal and vertical scaling?", a: "Horizontal adds more instances, vertical adds more power", options: ["Horizontal adds more instances, vertical adds more power", "Horizontal is always better", "Vertical is always cheaper", "No practical difference"], explanation: "Horizontal scaling adds more instances of resources, while vertical scaling increases the power (CPU, RAM) of existing instances." },
                        { q: "What is AWS Route 53 used for?", a: "Domain Name System (DNS) web service", options: ["Load balancing only", "Domain Name System (DNS) web service", "Content delivery", "Database routing"], explanation: "Route 53 is AWS's scalable DNS web service designed to route end users to Internet applications reliably." },
                        { q: "What is the purpose of AWS Elastic Load Balancer?", a: "Distribute incoming traffic across multiple targets", options: ["Store static files", "Distribute incoming traffic across multiple targets", "Monitor application performance", "Manage user authentication"], explanation: "Elastic Load Balancing automatically distributes incoming application traffic across multiple targets, such as EC2 instances." },
                        { q: "Which GCP service is equivalent to AWS CloudFormation?", a: "Deployment Manager", options: ["Cloud Build", "Deployment Manager", "Cloud Composer", "Resource Manager"], explanation: "Google Cloud Deployment Manager allows you to specify all resources needed for your application in a declarative format using YAML." },
                        { q: "What is the difference between S3 Standard and S3 Standard-IA?", a: "Standard-IA is for infrequently accessed data with lower cost", options: ["Standard-IA is faster", "Standard-IA is for infrequently accessed data with lower cost", "Standard-IA has better durability", "No difference"], explanation: "S3 Standard-IA (Infrequent Access) offers lower storage costs for data accessed less frequently but requires rapid access when needed." },
                        { q: "What is AWS API Gateway used for?", a: "Creating and managing APIs", options: ["Database management", "Creating and managing APIs", "File storage", "User authentication"], explanation: "API Gateway is a fully managed service for creating, publishing, maintaining, monitoring, and securing REST, HTTP, and WebSocket APIs." },
                        { q: "Which AWS service provides managed message queuing?", a: "SQS", options: ["SNS", "SQS", "SES", "Kinesis"], explanation: "SQS (Simple Queue Service) is a fully managed message queuing service that enables decoupling and scaling of microservices." },
                        { q: "What is the purpose of AWS CloudTrail?", a: "API logging and monitoring", options: ["Performance monitoring", "API logging and monitoring", "Cost optimization", "Security scanning"], explanation: "CloudTrail provides governance, compliance, operational auditing, and risk auditing of your AWS account by logging API calls." },
                        { q: "Which GCP service provides managed Apache Spark and Hadoop?", a: "Dataproc", options: ["BigQuery", "Dataflow", "Dataproc", "Cloud Composer"], explanation: "Dataproc is a fast, easy-to-use, fully managed cloud service for running Apache Spark and Apache Hadoop clusters." },
                        { q: "What is AWS Elastic Beanstalk?", a: "Platform-as-a-Service for deploying applications", options: ["Infrastructure monitoring", "Platform-as-a-Service for deploying applications", "Database service", "Content delivery network"], explanation: "Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications and services with popular development platforms." },
                        { q: "What is the difference between AWS SNS and SQS?", a: "SNS is pub/sub messaging, SQS is message queuing", options: ["SNS is faster", "SNS is pub/sub messaging, SQS is message queuing", "SQS is more reliable", "No difference"], explanation: "SNS (Simple Notification Service) is a pub/sub messaging service, while SQS provides message queuing for decoupling applications." },
                        { q: "Which AWS service provides managed Apache Kafka?", a: "MSK (Managed Streaming for Kafka)", options: ["Kinesis", "SQS", "MSK (Managed Streaming for Kafka)", "SNS"], explanation: "Amazon MSK is a fully managed service that makes it easy to build and run applications that use Apache Kafka." },
                        { q: "What is AWS CodePipeline used for?", a: "Continuous integration and continuous delivery", options: ["Code storage", "Continuous integration and continuous delivery", "Code editing", "Code documentation"], explanation: "CodePipeline is a continuous integration and continuous delivery service for fast and reliable application and infrastructure updates." }
                    ],
                    3: [
                        { q: "What does the CAP theorem state about distributed systems?", a: "You can only guarantee 2 of 3: Consistency, Availability, Partition tolerance", options: ["You can only guarantee 2 of 3: Consistency, Availability, Partition tolerance", "All three can be guaranteed simultaneously", "Only applies to SQL databases", "Related to network security"], explanation: "The CAP theorem proves that distributed systems can only guarantee two of three properties: Consistency, Availability, and Partition tolerance." },
                        { q: "How would you design a multi-region disaster recovery strategy in AWS?", a: "Use cross-region replication, backup strategies, and failover mechanisms", options: ["Just backup data regularly", "Use cross-region replication, backup strategies, and failover mechanisms", "Keep everything in one region", "Only use local backups"], explanation: "Multi-region DR requires cross-region data replication, automated failover, backup strategies, and regular testing of recovery procedures." },
                        { q: "What is the difference between AWS Transit Gateway and VPC Peering?", a: "Transit Gateway provides centralized connectivity, VPC Peering is point-to-point", options: ["Transit Gateway is slower", "Transit Gateway provides centralized connectivity, VPC Peering is point-to-point", "No practical difference", "VPC Peering is more secure"], explanation: "Transit Gateway acts as a hub for connecting VPCs and on-premises networks, while VPC Peering creates direct connections between two VPCs." },
                        { q: "How would you implement blue-green deployment in the cloud?", a: "Maintain two identical environments and switch traffic between them", options: ["Use different colored servers", "Maintain two identical environments and switch traffic between them", "Deploy only during off-hours", "Use A/B testing"], explanation: "Blue-green deployment maintains two identical production environments, allowing instant switching with zero downtime and easy rollback." },
                        { q: "What are the security best practices for cloud IAM?", a: "Principle of least privilege, MFA, regular rotation, monitoring", options: ["Give everyone admin access", "Principle of least privilege, MFA, regular rotation, monitoring", "Use only root accounts", "Disable all logging"], explanation: "IAM security requires least privilege access, multi-factor authentication, regular credential rotation, and comprehensive monitoring." },
                        { q: "How do you optimize costs in a cloud environment?", a: "Right-sizing, reserved instances, auto-scaling, monitoring unused resources", options: ["Always use the largest instances", "Right-sizing, reserved instances, auto-scaling, monitoring unused resources", "Keep all resources running", "Only use on-demand pricing"], explanation: "Cost optimization involves right-sizing resources, using reserved instances, implementing auto-scaling, and regularly monitoring for unused resources." },
                        { q: "What is the difference between stateful and stateless applications in cloud architecture?", a: "Stateless apps don't store session data, stateful apps do", options: ["Stateless apps are slower", "Stateless apps don't store session data, stateful apps do", "Stateful apps are more secure", "No practical difference"], explanation: "Stateless applications don't store session information between requests, making them easier to scale and more fault-tolerant than stateful applications." },
                        { q: "How would you implement a microservices architecture in the cloud?", a: "Use containers, service mesh, API gateways, and independent databases", options: ["Use a single large server", "Use containers, service mesh, API gateways, and independent databases", "Keep everything in one database", "Avoid using containers"], explanation: "Microservices architecture requires containerization, service mesh for communication, API gateways for routing, and database per service pattern." },
                        { q: "What is eventual consistency in distributed systems?", a: "System will become consistent over time without immediate consistency", options: ["Data is always immediately consistent", "System will become consistent over time without immediate consistency", "Data is never consistent", "Only applies to NoSQL databases"], explanation: "Eventual consistency guarantees that if no new updates are made, all replicas will eventually converge to the same value." },
                        { q: "How do you implement observability in cloud applications?", a: "Combine metrics, logs, and traces with monitoring tools", options: ["Only use basic logging", "Combine metrics, logs, and traces with monitoring tools", "Just monitor CPU usage", "Observability is not necessary"], explanation: "Observability requires the three pillars: metrics (numerical data), logs (event records), and traces (request flows) with appropriate monitoring tools." },
                        { q: "What are the challenges of container orchestration at scale?", a: "Service discovery, load balancing, health monitoring, security, networking", options: ["Containers are always easy to manage", "Service discovery, load balancing, health monitoring, security, networking", "No challenges exist", "Only storage is challenging"], explanation: "Container orchestration at scale requires managing service discovery, load balancing, health monitoring, security policies, and complex networking." },
                        { q: "How would you design a highly available database architecture?", a: "Use read replicas, multi-AZ deployment, automated backups, and failover", options: ["Use a single database instance", "Use read replicas, multi-AZ deployment, automated backups, and failover", "Databases don't need high availability", "Manual backups are sufficient"], explanation: "High availability databases require read replicas for scaling, multi-AZ deployment for redundancy, automated backups, and automatic failover mechanisms." },
                        { q: "What is the shared responsibility model in cloud security?", a: "Cloud provider secures infrastructure, customer secures data and applications", options: ["Cloud provider handles all security", "Cloud provider secures infrastructure, customer secures data and applications", "Customer handles all security", "Security is not important in cloud"], explanation: "The shared responsibility model divides security duties: cloud providers secure the infrastructure, customers secure their data, applications, and configurations." },
                        { q: "How do you implement zero-downtime deployments?", a: "Use rolling updates, canary deployments, or blue-green strategies", options: ["Accept downtime as normal", "Use rolling updates, canary deployments, or blue-green strategies", "Deploy only at night", "Stop all services during deployment"], explanation: "Zero-downtime deployments use strategies like rolling updates, canary deployments, or blue-green deployments to update applications without service interruption." },
                        { q: "What are the considerations for cloud vendor lock-in?", a: "Use open standards, abstract vendor-specific services, plan exit strategies", options: ["Vendor lock-in is always bad", "Use open standards, abstract vendor-specific services, plan exit strategies", "Lock-in is unavoidable", "Only use proprietary services"], explanation: "Avoiding vendor lock-in requires using open standards, abstracting vendor-specific services, maintaining portable architectures, and planning exit strategies." },
                        { q: "How do you implement compliance and governance in cloud environments?", a: "Use policy as code, compliance frameworks, audit trails, and automated scanning", options: ["Compliance is not necessary", "Use policy as code, compliance frameworks, audit trails, and automated scanning", "Manual processes are sufficient", "Governance slows down development"], explanation: "Cloud governance requires policy as code implementation, compliance framework adoption, comprehensive audit trails, and automated security scanning." }
                    ]
                },
                mlops: {
                    1: [
                        { q: "What does MLOps stand for?", a: "Machine Learning Operations", options: ["Machine Learning Operations", "Machine Learning Optimization", "Multi-Layer Operations", "Model Learning Operations"], explanation: "MLOps combines Machine Learning with Operations, focusing on the deployment, monitoring, and maintenance of ML models in production." },
                        { q: "What is model drift?", a: "Performance degradation over time due to data changes", options: ["Model becoming too complex", "Performance degradation over time due to data changes", "Model taking too long to train", "Model using too much memory"], explanation: "Model drift occurs when a model's performance decreases over time because the real-world data differs from the training data." },
                        { q: "What is the purpose of A/B testing in ML?", a: "Compare performance of different models", options: ["Debug code errors", "Compare performance of different models", "Optimize training speed", "Reduce model size"], explanation: "A/B testing compares the performance of different ML models by splitting traffic and measuring business metrics and model accuracy." },
                        { q: "What is continuous integration in machine learning?", a: "Automated testing and integration of ML code changes", options: ["Manual code reviews", "Automated testing and integration of ML code changes", "Continuous data collection", "Continuous model training"], explanation: "CI in ML involves automated testing of code changes, data validation, model testing, and integration with the ML pipeline." },
                        { q: "What is model versioning?", a: "Tracking different versions of ML models", options: ["Tracking different versions of ML models", "Updating model parameters", "Model performance monitoring", "Model size optimization"], explanation: "Model versioning tracks different iterations of ML models, including their code, data, hyperparameters, and performance metrics." },
                        { q: "What is the purpose of feature stores?", a: "Centralized repository for ML features", options: ["Storing raw data", "Centralized repository for ML features", "Model storage", "Code repository"], explanation: "Feature stores provide a centralized repository for storing, managing, and serving features for ML models, ensuring consistency and reusability." },
                        { q: "What is model monitoring?", a: "Tracking model performance and behavior in production", options: ["Tracking model performance and behavior in production", "Monitoring server resources", "Watching model training", "Code debugging"], explanation: "Model monitoring involves tracking model performance, data quality, prediction accuracy, and system health in production environments." },
                        { q: "What is a model registry?", a: "Centralized repository for storing and managing ML models", options: ["Database for training data", "Centralized repository for storing and managing ML models", "Code version control", "Feature documentation"], explanation: "A model registry is a centralized repository that stores, versions, and manages ML models along with their metadata and lineage information." },
                        { q: "What is the difference between training and inference pipelines?", a: "Training builds models, inference serves predictions", options: ["Training builds models, inference serves predictions", "Training is faster than inference", "Inference requires more data", "No practical difference"], explanation: "Training pipelines build and validate models using historical data, while inference pipelines serve real-time or batch predictions using trained models." },
                        { q: "What is model lineage?", a: "Tracking the origin and evolution of models", options: ["Model family relationships", "Tracking the origin and evolution of models", "Model performance metrics", "Model deployment history"], explanation: "Model lineage tracks the complete history of a model including data sources, transformations, training processes, and deployment information." },
                        { q: "What is automated machine learning (AutoML)?", a: "Automating the ML model development process", options: ["Manual model selection", "Automating the ML model development process", "Automatic data collection", "Self-learning algorithms"], explanation: "AutoML automates various aspects of the ML workflow including feature selection, model selection, hyperparameter tuning, and architecture search." },
                        { q: "What is model reproducibility?", a: "Ability to recreate the same model results", options: ["Model running multiple times", "Ability to recreate the same model results", "Model copying functionality", "Model backup and restore"], explanation: "Model reproducibility ensures that ML experiments can be recreated with the same results by tracking code, data, environment, and random seeds." },
                        { q: "What is the purpose of data validation in ML pipelines?", a: "Ensuring data quality and consistency", options: ["Ensuring data quality and consistency", "Data storage optimization", "Data visualization", "Data encryption"], explanation: "Data validation checks for data quality issues, schema changes, statistical anomalies, and ensures data consistency throughout the ML pipeline." },
                        { q: "What is model serving?", a: "Deploying models to make predictions on new data", options: ["Training models on servers", "Deploying models to make predictions on new data", "Storing models in databases", "Model performance testing"], explanation: "Model serving is the process of deploying trained ML models to production environments where they can receive requests and return predictions." },
                        { q: "What is the difference between online and offline inference?", a: "Online is real-time, offline is batch processing", options: ["Online is faster", "Online is real-time, offline is batch processing", "Offline is more accurate", "No practical difference"], explanation: "Online inference provides real-time predictions for individual requests, while offline inference processes large batches of data periodically." },
                        { q: "What is model deployment?", a: "Making trained models available in production", options: ["Training models", "Making trained models available in production", "Model testing", "Data preprocessing"], explanation: "Model deployment involves taking a trained model and making it available in a production environment to serve predictions to applications or users." },
                        { q: "What is MLOps pipeline orchestration?", a: "Managing workflow and dependencies of ML processes", options: ["Playing ML music", "Managing workflow and dependencies of ML processes", "ML pipeline construction", "Orchestra for ML"], explanation: "Pipeline orchestration manages the scheduling, execution order, and dependencies of various ML workflow steps from data ingestion to model deployment." }
                    ],
                    2: [
                        { q: "What is the difference between data drift and concept drift?", a: "Data drift is input distribution changes, concept drift is relationship changes", options: ["No practical difference", "Data drift is input distribution changes, concept drift is relationship changes", "Data drift is worse than concept drift", "Concept drift only affects deep learning"], explanation: "Data drift refers to changes in input feature distributions, while concept drift refers to changes in the relationship between inputs and outputs." },
                        { q: "What is a feature store in MLOps?", a: "Centralized repository for ML features", options: ["Database for storing models", "Centralized repository for ML features", "Training data warehouse", "Model versioning system"], explanation: "A feature store is a centralized repository that stores, manages, and serves features for machine learning models, enabling feature reuse and consistency." },
                        { q: "What is continuous deployment in ML?", a: "Automated deployment of ML models to production", options: ["Manual model updates", "Automated deployment of ML models to production", "Continuous data collection", "Continuous model training"], explanation: "Continuous deployment in ML involves automatically deploying validated models to production environments without manual intervention." },
                        { q: "What is model governance?", a: "Policies and processes for managing ML models", options: ["Model performance optimization", "Policies and processes for managing ML models", "Model training acceleration", "Feature engineering"], explanation: "Model governance encompasses the policies, processes, and controls for managing ML models throughout their lifecycle, including compliance and risk management." },
                        { q: "What is shadow mode deployment?", a: "Running new model alongside production without affecting users", options: ["Deploying at night only", "Running new model alongside production without affecting users", "Hidden model features", "Encrypted model deployment"], explanation: "Shadow mode deployment runs a new model in parallel with the production model to compare performance without affecting user experience." },
                        { q: "What is model performance degradation?", a: "Decline in model accuracy over time", options: ["Model running slower", "Decline in model accuracy over time", "Model using more memory", "Model training issues"], explanation: "Model performance degradation occurs when a model's predictive accuracy decreases over time due to changes in data patterns or business conditions." },
                        { q: "What is canary deployment for ML models?", a: "Gradual rollout to a subset of users", options: ["Deploying yellow-colored models", "Gradual rollout to a subset of users", "Emergency deployment process", "Backup deployment strategy"], explanation: "Canary deployment gradually routes a small percentage of traffic to a new model version while monitoring performance before full rollout." },
                        { q: "What is model explainability in MLOps?", a: "Understanding why models make specific predictions", options: ["Model documentation", "Understanding why models make specific predictions", "Model debugging", "Performance optimization"], explanation: "Model explainability provides insights into how and why ML models make specific predictions, crucial for trust and compliance in production systems." },
                        { q: "What is automated retraining?", a: "Automatically retraining models when performance drops", options: ["Manual model updates", "Automatically retraining models when performance drops", "Continuous data collection", "Model backup processes"], explanation: "Automated retraining triggers model retraining processes when performance metrics fall below thresholds or when new data patterns are detected." },
                        { q: "What is model orchestration?", a: "Managing workflow and dependencies of ML pipelines", options: ["Model performance tuning", "Managing workflow and dependencies of ML pipelines", "Model storage management", "Feature selection"], explanation: "Model orchestration manages the workflow, scheduling, and dependencies of ML pipelines, ensuring proper execution order and resource allocation." },
                        { q: "What is blue-green deployment for ML?", a: "Maintaining two identical environments for zero-downtime deployment", options: ["Using blue and green colors", "Maintaining two identical environments for zero-downtime deployment", "Environmental deployment", "Color-coded features"], explanation: "Blue-green deployment maintains two identical production environments, allowing instant switching between model versions with zero downtime." },
                        { q: "What is model bias monitoring?", a: "Detecting unfair treatment of different groups", options: ["Monitoring model preferences", "Detecting unfair treatment of different groups", "Performance monitoring", "Resource usage monitoring"], explanation: "Model bias monitoring detects when ML models treat different demographic or categorical groups unfairly, ensuring equitable outcomes." },
                        { q: "What is feature drift?", a: "Changes in feature distributions over time", options: ["Features moving physically", "Changes in feature distributions over time", "Feature deletion", "Feature renaming"], explanation: "Feature drift occurs when the statistical properties of input features change over time, potentially affecting model performance." },
                        { q: "What is model rollback?", a: "Reverting to a previous model version", options: ["Rolling models backward", "Reverting to a previous model version", "Model training restart", "Data preprocessing reset"], explanation: "Model rollback is the process of reverting to a previous model version when the current version performs poorly or causes issues in production." },
                        { q: "What is A/B testing in ML deployment?", a: "Comparing performance of different models with live traffic", options: ["Testing models on datasets A and B", "Comparing performance of different models with live traffic", "Alphabetical model testing", "Binary model comparison"], explanation: "A/B testing in ML compares different model versions by splitting live traffic and measuring business metrics and model performance." },
                        { q: "What is model containerization?", a: "Packaging models with their dependencies", options: ["Storing models in boxes", "Packaging models with their dependencies", "Model compression", "Model encryption"], explanation: "Model containerization packages ML models with their runtime dependencies, libraries, and configurations for consistent deployment across environments." },
                        { q: "What is MLOps maturity model?", a: "Framework for assessing MLOps implementation levels", options: ["Model maturity assessment", "Framework for assessing MLOps implementation levels", "Mature ML models", "MLOps age measurement"], explanation: "MLOps maturity models provide frameworks for organizations to assess their current MLOps capabilities and plan improvements across different dimensions." }
                    ],
                    3: [
                        { q: "How would you implement canary deployment for ML models?", a: "Gradually route traffic from old to new model while monitoring metrics", options: ["Replace all traffic at once", "Gradually route traffic from old to new model while monitoring metrics", "Only deploy during off-peak hours", "Use blue-green deployment instead"], explanation: "Canary deployment gradually shifts traffic to the new model while monitoring performance metrics, allowing safe rollback if issues arise." },
                        { q: "What are the key components of ML model governance?", a: "Model versioning, lineage tracking, approval workflows, and compliance monitoring", options: ["Just version control", "Model versioning, lineage tracking, approval workflows, and compliance monitoring", "Only performance monitoring", "Just data quality checks"], explanation: "ML governance requires model versioning, complete lineage tracking, approval workflows for deployments, and continuous compliance monitoring." },
                        { q: "How do you implement automated model retraining?", a: "Monitor performance metrics, detect degradation, trigger retraining pipelines", options: ["Retrain models daily", "Monitor performance metrics, detect degradation, trigger retraining pipelines", "Manual retraining only", "Never retrain models"], explanation: "Automated retraining monitors model performance, detects degradation patterns, and triggers retraining workflows with new data when needed." },
                        { q: "What is the difference between model-centric and data-centric AI?", a: "Model-centric focuses on algorithms, data-centric focuses on data quality", options: ["No difference", "Model-centric focuses on algorithms, data-centric focuses on data quality", "Model-centric is always better", "Data-centric is newer"], explanation: "Model-centric AI emphasizes improving algorithms and architectures, while data-centric AI focuses on improving data quality and consistency." },
                        { q: "How do you handle model versioning in production environments?", a: "Semantic versioning, metadata tracking, automated testing, rollback capabilities", options: ["Just number versions sequentially", "Semantic versioning, metadata tracking, automated testing, rollback capabilities", "Version control is unnecessary", "Manual version tracking"], explanation: "Production model versioning requires semantic versioning, comprehensive metadata, automated testing pipelines, and reliable rollback mechanisms." },
                        { q: "What are the challenges of multi-model deployment?", a: "Resource management, latency optimization, model coordination, monitoring complexity", options: ["No challenges exist", "Resource management, latency optimization, model coordination, monitoring complexity", "Just storage issues", "Only networking problems"], explanation: "Multi-model deployment faces challenges in resource allocation, latency optimization, inter-model coordination, and complex monitoring requirements." },
                        { q: "How do you implement feature store architecture?", a: "Offline store for training, online store for serving, feature transformation pipeline", options: ["Single database for everything", "Offline store for training, online store for serving, feature transformation pipeline", "Only online storage", "Manual feature management"], explanation: "Feature store architecture includes offline storage for training, online storage for low-latency serving, and transformation pipelines for consistency." },
                        { q: "What is model drift detection and how do you implement it?", a: "Statistical tests comparing training and production data distributions", options: ["Visual inspection only", "Statistical tests comparing training and production data distributions", "Manual performance reviews", "Drift detection is impossible"], explanation: "Model drift detection uses statistical tests to compare production data distributions with training data, triggering alerts when significant changes occur." },
                        { q: "How do you ensure reproducibility in ML experiments?", a: "Version control code/data, track environment, log parameters, use seeds", options: ["Reproducibility is impossible", "Version control code/data, track environment, log parameters, use seeds", "Just save model files", "Manual documentation"], explanation: "ML reproducibility requires versioning code and data, tracking environment configurations, logging all parameters, and controlling random seeds." },
                        { q: "What is the role of MLOps in regulatory compliance?", a: "Audit trails, model explainability, bias monitoring, documentation", options: ["Compliance is not needed", "Audit trails, model explainability, bias monitoring, documentation", "Just legal approval", "Compliance slows development"], explanation: "MLOps enables regulatory compliance through comprehensive audit trails, model explainability, bias monitoring, and proper documentation." },
                        { q: "How do you implement real-time model monitoring?", a: "Stream processing, alerting systems, dashboard visualization, automated responses", options: ["Manual checking", "Stream processing, alerting systems, dashboard visualization, automated responses", "Monitoring is unnecessary", "Daily batch reports only"], explanation: "Real-time monitoring requires stream processing for live data, alerting systems for anomalies, visual dashboards, and automated response mechanisms." },
                        { q: "What are the key metrics for MLOps pipeline health?", a: "Model accuracy, latency, throughput, error rates, data quality", options: ["Only accuracy matters", "Model accuracy, latency, throughput, error rates, data quality", "Just system uptime", "No metrics needed"], explanation: "MLOps pipeline health requires monitoring model accuracy, prediction latency, system throughput, error rates, and data quality metrics." },
                        { q: "How do you handle model dependencies in production?", a: "Containerization, dependency locking, environment isolation, version compatibility", options: ["Dependencies don't matter", "Containerization, dependency locking, environment isolation, version compatibility", "Manual dependency management", "Always use latest versions"], explanation: "Managing model dependencies requires containerization, dependency version locking, environment isolation, and compatibility testing." },
                        { q: "What is the difference between online and batch model serving?", a: "Online serves individual requests, batch processes large datasets", options: ["Online is always faster", "Online serves individual requests, batch processes large datasets", "Batch is more accurate", "No practical difference"], explanation: "Online serving provides real-time predictions for individual requests, while batch serving processes large datasets efficiently in scheduled jobs." },
                        { q: "How do you implement model security in MLOps?", a: "Access controls, model encryption, audit logging, vulnerability scanning", options: ["Security is not important", "Access controls, model encryption, audit logging, vulnerability scanning", "Just use passwords", "Physical security only"], explanation: "Model security requires role-based access controls, model encryption at rest and in transit, comprehensive audit logging, and regular vulnerability scanning." },
                        { q: "What are the best practices for ML model testing?", a: "Unit tests, integration tests, data validation, performance benchmarks", options: ["Testing is unnecessary", "Unit tests, integration tests, data validation, performance benchmarks", "Manual testing only", "Just accuracy testing"], explanation: "ML model testing includes unit tests for code, integration tests for pipelines, data validation checks, and performance benchmark comparisons." }
                    ]
                },
                modeling: {
                    1: [
                        { q: "What is overfitting in machine learning?", a: "Model performs well on training data but poorly on test data", options: ["Model is too simple", "Model performs well on training data but poorly on test data", "Model trains too slowly", "Model uses too much memory"], explanation: "Overfitting occurs when a model learns the training data too specifically, including noise, making it perform poorly on new, unseen data." },
                        { q: "What is the purpose of regularization?", a: "Prevent overfitting by adding penalty to model complexity", options: ["Speed up training", "Prevent overfitting by adding penalty to model complexity", "Improve data quality", "Reduce memory usage"], explanation: "Regularization adds penalties for model complexity to the loss function, helping prevent overfitting by encouraging simpler models." },
                        { q: "What is cross-validation?", a: "Technique to assess model performance using multiple train/test splits", options: ["Method to clean data", "Technique to assess model performance using multiple train/test splits", "Way to select features", "Process to optimize hyperparameters"], explanation: "Cross-validation evaluates model performance by splitting data into multiple folds and testing on each fold while training on the others." },
                        { q: "What is a confusion matrix?", a: "Table showing actual vs predicted classifications", options: ["Matrix of confusing data points", "Table showing actual vs predicted classifications", "Feature correlation matrix", "Model weight matrix"], explanation: "A confusion matrix displays the performance of a classification model by showing actual versus predicted class labels." },
                        { q: "What is feature selection?", a: "Choosing the most relevant features for model training", options: ["Selecting model parameters", "Choosing the most relevant features for model training", "Picking training algorithms", "Selecting data samples"], explanation: "Feature selection identifies and selects the most relevant features that contribute to model performance while removing irrelevant ones." },
                        { q: "What is the difference between classification and regression?", a: "Classification predicts categories, regression predicts continuous values", options: ["Classification is faster", "Classification predicts categories, regression predicts continuous values", "Regression is more accurate", "No practical difference"], explanation: "Classification predicts discrete categories or classes, while regression predicts continuous numerical values." },
                        { q: "What is a decision tree?", a: "Tree-like model that makes decisions based on feature conditions", options: ["Database structure", "Tree-like model that makes decisions based on feature conditions", "Visualization tool", "Data storage format"], explanation: "Decision trees use a tree-like structure to make predictions by following branches based on feature value conditions." },
                        { q: "What is ensemble learning?", a: "Combining multiple models to improve performance", options: ["Training one model multiple times", "Combining multiple models to improve performance", "Using ensemble datasets", "Parallel model training"], explanation: "Ensemble learning combines predictions from multiple models to achieve better performance than individual models." },
                        { q: "What is gradient descent?", a: "Optimization algorithm to minimize loss function", options: ["Feature scaling technique", "Optimization algorithm to minimize loss function", "Model validation method", "Data preprocessing step"], explanation: "Gradient descent is an iterative optimization algorithm that finds the minimum of a loss function by moving in the direction of steepest descent." },
                        { q: "What is the training-validation-test split?", a: "Dividing data into three sets for model development and evaluation", options: ["Three different algorithms", "Dividing data into three sets for model development and evaluation", "Three training phases", "Three model types"], explanation: "Data is split into training (model learning), validation (hyperparameter tuning), and test (final evaluation) sets." },
                        { q: "What is overfitting vs underfitting?", a: "Overfitting is too complex, underfitting is too simple", options: ["Overfitting is too complex, underfitting is too simple", "Overfitting is faster training", "Underfitting uses more data", "They're the same issue"], explanation: "Overfitting occurs when a model is too complex and memorizes training data, while underfitting occurs when a model is too simple to capture patterns." },
                        { q: "What is feature engineering?", a: "Creating new features from existing data", options: ["Model architecture design", "Creating new features from existing data", "Hyperparameter tuning", "Data collection process"], explanation: "Feature engineering involves creating, transforming, or selecting features from raw data to improve model performance." },
                        { q: "What is a learning curve?", a: "Plot showing model performance vs training set size", options: ["Algorithm complexity graph", "Plot showing model performance vs training set size", "Feature importance ranking", "Model architecture diagram"], explanation: "Learning curves plot model performance (accuracy/error) against training set size to diagnose bias and variance issues." },
                        { q: "What is hyperparameter tuning?", a: "Optimizing model configuration parameters", options: ["Adjusting data parameters", "Optimizing model configuration parameters", "Tuning hardware settings", "Adjusting feature weights"], explanation: "Hyperparameter tuning involves finding the best configuration parameters (learning rate, regularization, etc.) for optimal model performance." },
                        { q: "What is the curse of dimensionality?", a: "Performance degradation as feature dimensions increase", options: ["Too many models to choose from", "Performance degradation as feature dimensions increase", "Computational complexity issues", "Memory storage problems"], explanation: "The curse of dimensionality refers to various phenomena that arise when analyzing data in high-dimensional spaces, leading to sparse data and degraded performance." },
                        { q: "What is precision vs recall?", a: "Precision is true positives / predicted positives, recall is true positives / actual positives", options: ["Precision is accuracy, recall is speed", "Precision is true positives / predicted positives, recall is true positives / actual positives", "Precision is for regression, recall for classification", "No practical difference"], explanation: "Precision measures the accuracy of positive predictions, while recall measures the ability to find all actual positive instances." },
                        { q: "What is the F1 score?", a: "Harmonic mean of precision and recall", options: ["First feature importance score", "Harmonic mean of precision and recall", "Final model accuracy", "Feature selection metric"], explanation: "The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both measures." }
                    ],
                    2: [
                        { q: "What is the difference between L1 and L2 regularization?", a: "L1 creates sparse models, L2 shrinks weights evenly", options: ["No practical difference", "L1 creates sparse models, L2 shrinks weights evenly", "L2 is always better", "L1 only works with neural networks"], explanation: "L1 regularization can drive some weights to exactly zero (feature selection), while L2 regularization shrinks all weights proportionally towards zero." },
                        { q: "What is the bias-variance tradeoff?", a: "Balance between model's ability to fit training data vs generalize to new data", options: ["Choice between different algorithms", "Balance between model's ability to fit training data vs generalize to new data", "Speed vs accuracy tradeoff", "Memory vs performance tradeoff"], explanation: "The bias-variance tradeoff describes the balance between a model's ability to capture underlying patterns (bias) and its sensitivity to small changes in training data (variance)." },
                        { q: "What is bagging in ensemble methods?", a: "Bootstrap aggregating - training models on different data samples", options: ["Putting models in bags", "Bootstrap aggregating - training models on different data samples", "Model compression technique", "Feature selection method"], explanation: "Bagging trains multiple models on bootstrap samples of the training data and averages their predictions to reduce variance." },
                        { q: "What is boosting in machine learning?", a: "Sequential training where models learn from previous errors", options: ["Increasing model performance", "Sequential training where models learn from previous errors", "Parallel model training", "Model acceleration technique"], explanation: "Boosting sequentially trains models where each new model focuses on correcting errors made by previous models." },
                        { q: "What is random forest?", a: "Ensemble of decision trees with random feature selection", options: ["Trees planted randomly", "Ensemble of decision trees with random feature selection", "Random data sampling", "Randomized neural network"], explanation: "Random Forest combines multiple decision trees trained on random subsets of data and features, then averages their predictions." },
                        { q: "What is support vector machine (SVM)?", a: "Algorithm that finds optimal boundary between classes", options: ["Vector calculation method", "Algorithm that finds optimal boundary between classes", "Support system for models", "Matrix operation technique"], explanation: "SVM finds the optimal hyperplane that maximally separates different classes by maximizing the margin between them." },
                        { q: "What is k-means clustering?", a: "Unsupervised algorithm that groups data into k clusters", options: ["K different algorithms", "Unsupervised algorithm that groups data into k clusters", "K-fold validation method", "Feature selection technique"], explanation: "K-means partitions data into k clusters by minimizing within-cluster variance and maximizing between-cluster variance." },
                        { q: "What is principal component analysis (PCA)?", a: "Dimensionality reduction technique using principal components", options: ["Primary component analysis", "Dimensionality reduction technique using principal components", "Performance component assessment", "Process control analysis"], explanation: "PCA reduces dimensionality by finding principal components that capture the most variance in the data." },
                        { q: "What is the ROC curve?", a: "Plot of true positive rate vs false positive rate", options: ["Receiver operating characteristic", "Plot of true positive rate vs false positive rate", "Rate of change curve", "Regression output curve"], explanation: "ROC curves plot the true positive rate against false positive rate at various threshold settings, helping evaluate binary classifiers." },
                        { q: "What is AUC in machine learning?", a: "Area under the ROC curve, measures classifier performance", options: ["Advanced unit calculation", "Area under the ROC curve, measures classifier performance", "Automated user classification", "Algorithm usage count"], explanation: "AUC (Area Under the Curve) measures the entire two-dimensional area underneath the ROC curve, providing a single scalar performance metric." },
                        { q: "What is stratified sampling?", a: "Sampling that maintains class proportions from original dataset", options: ["Sampling in layers", "Sampling that maintains class proportions from original dataset", "Random sampling method", "Sequential sampling technique"], explanation: "Stratified sampling ensures that each class is represented proportionally in the sample as they appear in the original dataset." },
                        { q: "What is feature scaling?", a: "Normalizing features to similar ranges", options: ["Scaling model size", "Normalizing features to similar ranges", "Feature importance ranking", "Feature selection process"], explanation: "Feature scaling transforms features to similar scales (like 0-1 or standard normal) to ensure no feature dominates due to its scale." },
                        { q: "What is cross-entropy loss?", a: "Loss function commonly used for classification problems", options: ["Cross-validation error", "Loss function commonly used for classification problems", "Entropy between datasets", "Cross-feature correlation"], explanation: "Cross-entropy loss measures the difference between predicted probability distributions and true class labels in classification." },
                        { q: "What is early stopping?", a: "Stopping training when validation performance stops improving", options: ["Stopping training early to save time", "Stopping training when validation performance stops improving", "Emergency training halt", "Scheduled training termination"], explanation: "Early stopping prevents overfitting by monitoring validation performance and stopping training when it begins to degrade." },
                        { q: "What is batch vs stochastic gradient descent?", a: "Batch uses all data, stochastic uses one sample per update", options: ["Batch is faster", "Batch uses all data, stochastic uses one sample per update", "Stochastic is more accurate", "No practical difference"], explanation: "Batch gradient descent uses the entire dataset for each update, while stochastic gradient descent uses one sample at a time." },
                        { q: "What is dropout in neural networks?", a: "Randomly setting some neurons to zero during training", options: ["Removing bad data points", "Randomly setting some neurons to zero during training", "Stopping training early", "Dropping unnecessary features"], explanation: "Dropout randomly sets a fraction of neurons to zero during training to prevent overfitting and improve generalization." }
                    ],
                    3: [
                        { q: "How would you handle class imbalance in a dataset?", a: "Use techniques like SMOTE, class weights, or different evaluation metrics", options: ["Ignore the imbalance", "Use techniques like SMOTE, class weights, or different evaluation metrics", "Always use more data", "Only use precision as metric"], explanation: "Class imbalance can be addressed through sampling techniques (SMOTE), adjusting class weights, using appropriate metrics (F1, AUC), or ensemble methods." },
                        { q: "What is the difference between bagging and boosting?", a: "Bagging trains models in parallel, boosting trains sequentially with error correction", options: ["No difference in practice", "Bagging trains models in parallel, boosting trains sequentially with error correction", "Bagging is always faster", "Boosting only works with decision trees"], explanation: "Bagging trains models independently in parallel and averages results, while boosting trains models sequentially where each corrects previous errors." },
                        { q: "How do you detect and handle overfitting?", a: "Monitor validation curves, use regularization, cross-validation, early stopping", options: ["Overfitting is always good", "Monitor validation curves, use regularization, cross-validation, early stopping", "Just use more data", "Overfitting cannot be detected"], explanation: "Overfitting detection involves monitoring training vs validation performance gaps and using techniques like regularization, cross-validation, and early stopping." },
                        { q: "What is transfer learning and when would you use it?", a: "Using pre-trained models as starting point, useful with limited data", options: ["Transferring data between models", "Using pre-trained models as starting point, useful with limited data", "Moving models between servers", "Transferring learning algorithms"], explanation: "Transfer learning leverages knowledge from pre-trained models, especially useful when you have limited training data for your specific task." },
                        { q: "How do you choose the right evaluation metric?", a: "Depends on problem type, class balance, business objectives, and costs", options: ["Always use accuracy", "Depends on problem type, class balance, business objectives, and costs", "Use the highest scoring metric", "Metrics don't matter"], explanation: "Metric selection depends on problem characteristics (classification/regression), class distribution, business goals, and relative costs of different error types." },
                        { q: "What is model interpretability and why is it important?", a: "Understanding how models make decisions, crucial for trust and compliance", options: ["Model documentation", "Understanding how models make decisions, crucial for trust and compliance", "Model performance measurement", "Model complexity assessment"], explanation: "Model interpretability helps understand decision-making processes, essential for building trust, debugging, and meeting regulatory requirements." },
                        { q: "How do you handle missing data in machine learning?", a: "Imputation, deletion, or algorithms that handle missing values", options: ["Always delete missing data", "Imputation, deletion, or algorithms that handle missing values", "Replace with zeros", "Missing data is not a problem"], explanation: "Missing data can be handled through various imputation techniques, careful deletion strategies, or using algorithms designed to work with missing values." },
                        { q: "What is feature importance and how do you measure it?", a: "Measures contribution of features, using permutation, SHAP, or model-specific methods", options: ["All features are equally important", "Measures contribution of features, using permutation, SHAP, or model-specific methods", "Feature importance is subjective", "Only applies to tree models"], explanation: "Feature importance quantifies how much each feature contributes to model predictions, measured through techniques like permutation importance, SHAP values, or model-specific methods." },
                        { q: "How do you optimize hyperparameters efficiently?", a: "Grid search, random search, Bayesian optimization, or automated methods", options: ["Trial and error only", "Grid search, random search, Bayesian optimization, or automated methods", "Use default values", "Hyperparameter optimization is unnecessary"], explanation: "Efficient hyperparameter optimization uses systematic approaches like grid search, random search, Bayesian optimization, or automated hyperparameter tuning tools." },
                        { q: "What are the challenges of deploying machine learning models?", a: "Data drift, model decay, scalability, monitoring, and infrastructure requirements", options: ["No challenges exist", "Data drift, model decay, scalability, monitoring, and infrastructure requirements", "Just technical implementation", "Only performance issues"], explanation: "ML deployment faces challenges including data distribution changes, model performance decay, scaling requirements, monitoring needs, and infrastructure complexity." },
                        { q: "How do you handle categorical variables in machine learning?", a: "One-hot encoding, label encoding, target encoding, or embeddings", options: ["Ignore categorical variables", "One-hot encoding, label encoding, target encoding, or embeddings", "Convert to numbers randomly", "Categorical variables cannot be used"], explanation: "Categorical variables require encoding techniques like one-hot encoding for nominal categories, label encoding for ordinal data, or more advanced methods like target encoding." },
                        { q: "What is the difference between online and batch learning?", a: "Online learns incrementally, batch learns from entire dataset at once", options: ["Online is faster", "Online learns incrementally, batch learns from entire dataset at once", "Batch is more accurate", "No practical difference"], explanation: "Online learning updates models incrementally with new data, while batch learning processes the entire dataset at once before updating the model." },
                        { q: "How do you validate time series models?", a: "Time-aware splits, walk-forward validation, avoiding data leakage", options: ["Standard cross-validation", "Time-aware splits, walk-forward validation, avoiding data leakage", "Random sampling", "Validation is not needed"], explanation: "Time series validation requires chronological data splits, walk-forward validation, and careful attention to prevent future data from leaking into past predictions." },
                        { q: "What is active learning?", a: "Strategically selecting most informative samples for labeling", options: ["Learning while active", "Strategically selecting most informative samples for labeling", "Continuous model training", "Interactive learning systems"], explanation: "Active learning strategically queries the most informative unlabeled examples for annotation, maximizing learning efficiency with minimal labeled data." },
                        { q: "How do you handle concept drift?", a: "Monitor performance, retrain models, use adaptive algorithms", options: ["Concept drift is not real", "Monitor performance, retrain models, use adaptive algorithms", "Ignore performance changes", "Use static models only"], explanation: "Concept drift requires continuous monitoring of model performance, periodic retraining, and potentially using adaptive algorithms that can adjust to changing patterns." },
                        { q: "What is multi-label vs multi-class classification?", a: "Multi-label allows multiple true labels, multi-class has one true label", options: ["They're the same thing", "Multi-label allows multiple true labels, multi-class has one true label", "Multi-class is more complex", "Multi-label is binary only"], explanation: "Multi-class classification has one correct class among many options, while multi-label classification can have multiple correct labels simultaneously." }
                    ]
                },                
                general: {
                    1: [
                        { q: "What are the three main types of machine learning?", a: "Supervised, Unsupervised, Reinforcement Learning", options: ["Supervised, Unsupervised, Reinforcement Learning", "Classification, Regression, Clustering", "Deep, Shallow, Medium Learning", "Fast, Slow, Medium Learning"], explanation: "The three main types are: Supervised (learning from labeled data), Unsupervised (finding patterns in unlabeled data), and Reinforcement Learning (learning through rewards)." },
                        { q: "What is artificial intelligence?", a: "Systems that can perform tasks requiring human-like intelligence", options: ["Only deep learning models", "Systems that can perform tasks requiring human-like intelligence", "Just computer programs", "Only neural networks"], explanation: "AI refers to computer systems that can perform tasks that typically require human intelligence, such as reasoning, learning, and problem-solving." },
                        { q: "What is the difference between AI, ML, and Deep Learning?", a: "AI is broadest, ML is subset of AI, Deep Learning is subset of ML", options: ["They're the same thing", "AI is broadest, ML is subset of AI, Deep Learning is subset of ML", "Deep Learning came first", "ML is broader than AI"], explanation: "AI is the broad concept of machines being able to carry out tasks intelligently. ML is a subset of AI using data to make decisions. Deep Learning is a subset of ML using neural networks." },
                        { q: "What is a neural network?", a: "Computing system inspired by biological neural networks", options: ["Network of computers", "Computing system inspired by biological neural networks", "Internet connection system", "Database structure"], explanation: "Neural networks are computing systems inspired by biological neural networks, consisting of interconnected nodes (neurons) that process information." },
                        { q: "What is supervised learning?", a: "Learning with labeled input-output pairs", options: ["Learning with a teacher present", "Learning with labeled input-output pairs", "Learning under supervision", "Guided learning process"], explanation: "Supervised learning uses labeled training data to learn a mapping from inputs to outputs, enabling predictions on new data." },
                        { q: "What is unsupervised learning?", a: "Finding patterns in data without labels", options: ["Learning without teachers", "Finding patterns in data without labels", "Unsupervised student learning", "Learning without guidance"], explanation: "Unsupervised learning discovers hidden patterns and structures in data without using labeled examples." },
                        { q: "What is reinforcement learning?", a: "Learning through trial and error with rewards and punishments", options: ["Strengthening existing knowledge", "Learning through trial and error with rewards and punishments", "Learning with reinforcement materials", "Repeated learning sessions"], explanation: "Reinforcement learning involves an agent learning optimal actions through trial and error, receiving rewards or punishments based on its decisions." },
                        { q: "What is an algorithm?", a: "Step-by-step instructions for solving a problem", options: ["Mathematical formula", "Step-by-step instructions for solving a problem", "Computer program", "Data structure"], explanation: "An algorithm is a finite sequence of well-defined instructions for accomplishing a task or solving a problem." },
                        { q: "What is big data?", a: "Large, complex datasets that require special tools to process", options: ["Data stored on big servers", "Large, complex datasets that require special tools to process", "Important business data", "Data with big impact"], explanation: "Big data refers to extremely large datasets that cannot be processed effectively with traditional data processing applications." },
                        { q: "What is computer vision?", a: "Field enabling computers to interpret visual information", options: ["Computer screen technology", "Field enabling computers to interpret visual information", "Vision correction software", "Computer graphics"], explanation: "Computer vision is a field that enables computers to gain high-level understanding from digital images or videos." },
                        { q: "What is natural language processing?", a: "Technology for computers to understand human language", options: ["Processing natural sounds", "Technology for computers to understand human language", "Language translation only", "Speech recognition only"], explanation: "NLP is a branch of AI that helps computers understand, interpret, and manipulate human language in a valuable way." },
                        { q: "What is machine learning?", a: "Systems that learn from data without explicit programming", options: ["Machines learning to work", "Systems that learn from data without explicit programming", "Teaching machines manually", "Automated machine operation"], explanation: "Machine learning enables computers to learn and make decisions from data without being explicitly programmed for every specific task." },
                        { q: "What is data mining?", a: "Discovering patterns and knowledge from large datasets", options: ["Mining data from databases", "Discovering patterns and knowledge from large datasets", "Extracting data from sources", "Data storage optimization"], explanation: "Data mining is the process of discovering patterns, correlations, and insights from large amounts of data using various analytical techniques." },
                        { q: "What is pattern recognition?", a: "Identifying regularities and structures in data", options: ["Recognizing visual patterns only", "Identifying regularities and structures in data", "Pattern matching in text", "Design pattern identification"], explanation: "Pattern recognition involves the automatic recognition of regularities in data through the use of computer algorithms." },
                        { q: "What is cognitive computing?", a: "Systems that simulate human thought processes", options: ["Fast computing systems", "Systems that simulate human thought processes", "Brain-computer interfaces", "Cognitive psychology software"], explanation: "Cognitive computing systems simulate human thought processes in computerized models using self-learning algorithms." },
                        { q: "What is expert system?", a: "AI system that emulates decision-making of human experts", options: ["System for experts only", "AI system that emulates decision-making of human experts", "Advanced computer system", "Professional software"], explanation: "Expert systems are AI programs that simulate the judgment and behavior of humans with expert knowledge in specific domains." },
                        { q: "What is the Turing Test?", a: "Test of machine's ability to exhibit intelligent behavior", options: ["Computer performance test", "Test of machine's ability to exhibit intelligent behavior", "Programming competency test", "Hardware reliability test"], explanation: "The Turing Test evaluates a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human." }
                    ],
                    2: [
                        { q: "What is transfer learning?", a: "Using pre-trained models as starting point for new tasks", options: ["Moving data between systems", "Using pre-trained models as starting point for new tasks", "Converting between model formats", "Sharing models between teams"], explanation: "Transfer learning leverages knowledge from pre-trained models on large datasets and applies it to new, often smaller, related tasks to improve performance and reduce training time." },
                        { q: "What is few-shot learning?", a: "Learning from very few examples", options: ["Fast training methods", "Learning from very few examples", "Using small models", "Quick inference techniques"], explanation: "Few-shot learning enables models to quickly adapt to new tasks with only a small number of training examples, mimicking human ability to learn from limited data." },
                        { q: "What is the attention mechanism?", a: "Way for models to focus on relevant parts of input", options: ["Error correction method", "Way for models to focus on relevant parts of input", "Training acceleration technique", "Memory optimization approach"], explanation: "Attention mechanisms allow models to dynamically focus on different parts of the input when making predictions, improving performance on complex tasks." },
                        { q: "What are transformer models?", a: "Architecture using self-attention for sequence processing", options: ["Models that transform data", "Architecture using self-attention for sequence processing", "Electrical transformer models", "Shape transformation algorithms"], explanation: "Transformers use self-attention mechanisms to process sequences, forming the basis for models like BERT and GPT." },
                        { q: "What is generative AI?", a: "AI that creates new content similar to training data", options: ["AI that generates power", "AI that creates new content similar to training data", "General-purpose AI", "AI generation process"], explanation: "Generative AI creates new content (text, images, audio) that resembles the patterns learned from training data." },
                        { q: "What is the difference between narrow and general AI?", a: "Narrow AI is specialized, general AI has human-level intelligence", options: ["Narrow AI is smaller", "Narrow AI is specialized, general AI has human-level intelligence", "General AI is more common", "No practical difference"], explanation: "Narrow AI is designed for specific tasks, while artificial general intelligence (AGI) would match human cognitive abilities across all domains." },
                        { q: "What is explainable AI (XAI)?", a: "AI systems that can provide clear explanations for decisions", options: ["AI that speaks multiple languages", "AI systems that can provide clear explanations for decisions", "AI with good documentation", "AI that's easy to install"], explanation: "Explainable AI refers to machine learning techniques that provide human-understandable explanations for their predictions and decisions." },
                        { q: "What is federated learning?", a: "Training models across decentralized data without sharing raw data", options: ["Learning in federal systems", "Training models across decentralized data without sharing raw data", "Collaborative learning groups", "Government AI training"], explanation: "Federated learning enables training machine learning models across distributed datasets without centralizing the data, preserving privacy." },
                        { q: "What is adversarial machine learning?", a: "Study of attacks on ML systems and defenses against them", options: ["Competitive ML competitions", "Study of attacks on ML systems and defenses against them", "Opposing AI systems", "Conflicting algorithms"], explanation: "Adversarial ML studies how to make machine learning systems robust against malicious attacks and deceptive inputs." },
                        { q: "What is meta-learning?", a: "Learning how to learn more effectively", options: ["Learning about learning", "Learning how to learn more effectively", "Metadata analysis", "Learning management systems"], explanation: "Meta-learning, or 'learning to learn,' focuses on designing models that can quickly adapt to new tasks with minimal training." },
                        { q: "What is continual learning?", a: "Learning new tasks without forgetting previous ones", options: ["Continuous training process", "Learning new tasks without forgetting previous ones", "Ongoing education", "Never-ending learning"], explanation: "Continual learning enables AI systems to learn new tasks sequentially while retaining knowledge from previous tasks, avoiding catastrophic forgetting." },
                        { q: "What is self-supervised learning?", a: "Learning from data without human-provided labels", options: ["AI teaching itself", "Learning from data without human-provided labels", "Automated supervision", "Independent learning systems"], explanation: "Self-supervised learning creates supervisory signals from the data itself, learning useful representations without manual labeling." },
                        { q: "What is multimodal AI?", a: "AI systems that process multiple types of data simultaneously", options: ["AI with multiple modes", "AI systems that process multiple types of data simultaneously", "Various AI models", "Flexible AI systems"], explanation: "Multimodal AI can process and understand multiple types of input data (text, images, audio) simultaneously to make more informed decisions." },
                        { q: "What is zero-shot learning?", a: "Making predictions on classes not seen during training", options: ["Learning with zero examples", "Making predictions on classes not seen during training", "Starting from scratch", "Learning without data"], explanation: "Zero-shot learning enables models to recognize and classify objects or concepts that were not present in the training data." },
                        { q: "What is curriculum learning?", a: "Training models with examples ordered from easy to difficult", options: ["Learning school curriculum", "Training models with examples ordered from easy to difficult", "Educational AI systems", "Structured learning programs"], explanation: "Curriculum learning trains models by gradually increasing the difficulty of training examples, similar to how humans learn." },
                        { q: "What is domain adaptation?", a: "Adapting models to work well in different but related domains", options: ["Changing internet domains", "Adapting models to work well in different but related domains", "Domain name management", "Website adaptation"], explanation: "Domain adaptation helps models trained in one domain perform well in a related but different domain where labeled data may be limited." }
                    ],
                    3: [
                        { q: "What are the key ethical considerations in AI development?", a: "Bias, fairness, privacy, transparency, and societal impact", options: ["Just accuracy metrics", "Bias, fairness, privacy, transparency, and societal impact", "Only computational costs", "Just legal compliance"], explanation: "AI ethics encompasses bias mitigation, ensuring fairness across groups, protecting privacy, maintaining transparency in decision-making, and considering broader societal impacts." },
                        { q: "What is the alignment problem in AI?", a: "Ensuring AI systems pursue intended goals safely", options: ["Aligning AI hardware", "Ensuring AI systems pursue intended goals safely", "Data alignment issues", "System synchronization"], explanation: "The AI alignment problem involves ensuring that advanced AI systems understand and safely pursue the goals intended by their human creators." },
                        { q: "What is artificial general intelligence (AGI)?", a: "AI with human-level cognitive abilities across all domains", options: ["Generally useful AI", "AI with human-level cognitive abilities across all domains", "AI for general public", "Generic AI systems"], explanation: "AGI refers to highly autonomous systems that outperform humans at most economically valuable work and possess general intelligence across domains." },
                        { q: "What is the singularity in AI context?", a: "Hypothetical point where AI surpasses human intelligence", options: ["Single AI system", "Hypothetical point where AI surpasses human intelligence", "Unique AI breakthrough", "Singular AI application"], explanation: "The technological singularity is a hypothetical point where artificial superintelligence triggers runaway technological growth beyond human comprehension." },
                        { q: "What is machine consciousness?", a: "Hypothetical subjective experiences in artificial systems", options: ["Machines being aware", "Hypothetical subjective experiences in artificial systems", "Conscious machine design", "Machine self-awareness"], explanation: "Machine consciousness refers to the hypothetical possibility of artificial systems having subjective experiences and phenomenal consciousness." },
                        { q: "What is the frame problem in AI?", a: "Challenge of representing what changes and what stays the same", options: ["Picture framing algorithms", "Challenge of representing what changes and what stays the same", "Framework selection issue", "Boundary definition problem"], explanation: "The frame problem involves determining what aspects of a situation remain unchanged when an action is performed, crucial for AI reasoning." },
                        { q: "What is the symbol grounding problem?", a: "How symbols in AI systems relate to real-world meaning", options: ["Symbol storage issues", "How symbols in AI systems relate to real-world meaning", "Mathematical symbol processing", "Symbol recognition problems"], explanation: "The symbol grounding problem questions how symbols in AI systems acquire meaning and connect to real-world objects and concepts." },
                        { q: "What is emergent behavior in AI?", a: "Complex behaviors arising from simple interactions", options: ["Emergency response AI", "Complex behaviors arising from simple interactions", "Emerging AI technologies", "Sudden behavioral changes"], explanation: "Emergent behavior occurs when complex systems exhibit properties or behaviors that arise from but are not directly predictable from their components." },
                        { q: "What is the Chinese Room argument?", a: "Philosophical argument against strong AI consciousness claims", options: ["AI developed in China", "Philosophical argument against strong AI consciousness claims", "Room-based AI systems", "Chinese language processing"], explanation: "The Chinese Room argument challenges whether computers can truly understand language or merely simulate understanding through symbol manipulation." },
                        { q: "What is computational complexity in AI?", a: "Study of resources required to solve computational problems", options: ["Complex AI computations", "Study of resources required to solve computational problems", "Complicated algorithms", "Computing difficulty levels"], explanation: "Computational complexity analyzes the time and space resources required to solve problems, crucial for understanding AI algorithm efficiency." },
                        { q: "What is the knowledge representation problem?", a: "How to store and organize knowledge for AI reasoning", options: ["Representing human knowledge", "How to store and organize knowledge for AI reasoning", "Knowledge database design", "Information representation"], explanation: "Knowledge representation involves developing formal languages and structures for storing and manipulating knowledge in AI systems." },
                        { q: "What is the combinatorial explosion problem?", a: "Exponential growth in possible solutions as problem size increases", options: ["Explosive AI growth", "Exponential growth in possible solutions as problem size increases", "Combining multiple explosions", "Computational overflow"], explanation: "Combinatorial explosion occurs when the number of possible combinations grows exponentially with problem size, making exhaustive search impractical." },
                        { q: "What is the moravec paradox?", a: "Tasks easy for humans can be hard for AI and vice versa", options: ["Paradox in Moravec's work", "Tasks easy for humans can be hard for AI and vice versa", "Contradictory AI results", "Paradoxical robot behavior"], explanation: "Moravec's paradox observes that high-level reasoning requires little computation, while low-level sensorimotor skills require enormous computational resources." },
                        { q: "What is swarm intelligence?", a: "Collective behavior of decentralized, self-organized systems", options: ["Intelligence of bee swarms", "Collective behavior of decentralized, self-organized systems", "Multiple AI systems", "Group AI intelligence"], explanation: "Swarm intelligence studies the collective behavior that emerges from groups of simple agents following local rules without centralized control." },
                        { q: "What is artificial life?", a: "Study of life-like processes in artificial systems", options: ["Creating artificial organisms", "Study of life-like processes in artificial systems", "Life support systems", "Biological AI"], explanation: "Artificial life investigates systems that exhibit behaviors characteristic of natural living systems through computer simulations and robotics." },
                        { q: "What is the hard problem of consciousness?", a: "Explaining subjective, qualitative aspects of mental states", options: ["Difficult consciousness research", "Explaining subjective, qualitative aspects of mental states", "Hard AI consciousness tasks", "Complex consciousness algorithms"], explanation: "The hard problem of consciousness involves explaining why and how physical processes give rise to subjective, qualitative experiences." }
                    ]
                },
                python_sql: {
                    1: [
                        { q: "Which Python library is primarily used for data manipulation?", a: "pandas", options: ["numpy", "pandas", "matplotlib", "scikit-learn"], explanation: "Pandas is the go-to library for data manipulation and analysis in Python, providing DataFrames and Series for structured data operations." },
                        { q: "What does 'SELECT DISTINCT' do in SQL?", a: "Returns unique values only", options: ["Sorts the results", "Returns unique values only", "Filters null values", "Joins multiple tables"], explanation: "SELECT DISTINCT removes duplicate rows from the result set, returning only unique values for the specified columns." },
                        { q: "How do you handle missing values in pandas?", a: "df.fillna() or df.dropna()", options: ["df.remove_na()", "df.fillna() or df.dropna()", "df.clean()", "df.null_handler()"], explanation: "Pandas provides fillna() to fill missing values with specified values and dropna() to remove rows/columns with missing values." },
                        { q: "What is the difference between a list and tuple in Python?", a: "Lists are mutable, tuples are immutable", options: ["Lists are faster", "Lists are mutable, tuples are immutable", "Tuples are larger", "No practical difference"], explanation: "Lists can be modified after creation (mutable), while tuples cannot be changed after creation (immutable)." },
                        { q: "What does GROUP BY do in SQL?", a: "Groups rows with same values for aggregate functions", options: ["Sorts data by groups", "Groups rows with same values for aggregate functions", "Creates data groups", "Groups database tables"], explanation: "GROUP BY groups rows that have the same values in specified columns, typically used with aggregate functions like COUNT, SUM, AVG." },
                        { q: "What is a Python dictionary?", a: "Collection of key-value pairs", options: ["List of definitions", "Collection of key-value pairs", "Book of terms", "Ordered sequence"], explanation: "A dictionary is an unordered collection of key-value pairs, where each key is unique and maps to a value." },
                        { q: "What is the difference between INNER JOIN and LEFT JOIN?", a: "INNER returns matching rows only, LEFT returns all left table rows", options: ["INNER is faster", "INNER returns matching rows only, LEFT returns all left table rows", "LEFT is more accurate", "No practical difference"], explanation: "INNER JOIN returns only rows with matches in both tables, while LEFT JOIN returns all rows from the left table plus matched rows from the right." },
                        { q: "What is list comprehension in Python?", a: "Concise way to create lists using loops and conditions", options: ["Understanding lists", "Concise way to create lists using loops and conditions", "List documentation", "List analysis method"], explanation: "List comprehension provides a concise way to create lists by applying expressions to items in an iterable, optionally with conditions." },
                        { q: "What is a primary key in SQL?", a: "Unique identifier for each row in a table", options: ["Most important column", "Unique identifier for each row in a table", "First column in table", "Key for opening database"], explanation: "A primary key is a column or combination of columns that uniquely identifies each row in a table and cannot contain NULL values." },
                        { q: "What is the difference between '==' and 'is' in Python?", a: "'==' compares values, 'is' compares object identity", options: ["They're identical", "'==' compares values, 'is' compares object identity", "'is' is faster", "'==' is more accurate"], explanation: "The '==' operator compares values for equality, while 'is' compares whether two variables point to the same object in memory." },
                        { q: "What does the WHERE clause do in SQL?", a: "Filters rows based on specified conditions", options: ["Shows table location", "Filters rows based on specified conditions", "Defines table structure", "Sets column names"], explanation: "The WHERE clause specifies conditions that must be met for rows to be included in the query results." },
                        { q: "What is a pandas DataFrame?", a: "2-dimensional labeled data structure", options: ["Data frame for photos", "2-dimensional labeled data structure", "Database framework", "Data visualization frame"], explanation: "A DataFrame is a 2-dimensional labeled data structure with columns that can contain different data types, similar to a spreadsheet or database table." },
                        { q: "What is a foreign key in SQL?", a: "Column that references primary key of another table", options: ["Key from another country", "Column that references primary key of another table", "Secondary key type", "External database key"], explanation: "A foreign key is a column that creates a link between two tables by referencing the primary key of another table." },
                        { q: "What is exception handling in Python?", a: "Managing errors using try/except blocks", options: ["Handling special cases", "Managing errors using try/except blocks", "Exception documentation", "Error prevention method"], explanation: "Exception handling uses try/except blocks to catch and handle errors gracefully without crashing the program." },
                        { q: "What is the difference between DELETE and TRUNCATE in SQL?", a: "DELETE removes specific rows, TRUNCATE removes all rows faster", options: ["DELETE is faster", "DELETE removes specific rows, TRUNCATE removes all rows faster", "TRUNCATE is safer", "No practical difference"], explanation: "DELETE removes specific rows based on conditions and can be rolled back, while TRUNCATE quickly removes all rows and cannot be rolled back." },
                        { q: "What is a lambda function in Python?", a: "Anonymous function defined inline", options: ["Greek letter function", "Anonymous function defined inline", "Lambda calculus implementation", "Mathematical function"], explanation: "Lambda functions are small anonymous functions defined inline, typically used for short, simple operations." },
                        { q: "What is normalization in databases?", a: "Organizing data to reduce redundancy", options: ["Making data normal", "Organizing data to reduce redundancy", "Standardizing data formats", "Normalizing data values"], explanation: "Database normalization organizes data to minimize redundancy and dependency by dividing large tables into smaller, related tables." }
                    ],
                    2: [
                        { q: "Which SQL clause is used for filtering grouped data?", a: "HAVING", options: ["WHERE", "HAVING", "GROUP BY", "ORDER BY"], explanation: "HAVING filters groups after GROUP BY aggregation, while WHERE filters individual rows before grouping." },
                        { q: "What is the difference between pandas merge() and join()?", a: "merge() is more flexible with multiple join types, join() uses index by default", options: ["No difference", "merge() is faster", "merge() is more flexible with multiple join types, join() uses index by default", "join() is deprecated"], explanation: "merge() offers more control over join keys and types, while join() is a convenient method that joins on index by default." },
                        { q: "What does pandas .apply() function do?", a: "Applies a function along axis of DataFrame", options: ["Applies a function along axis of DataFrame", "Filters DataFrame rows", "Sorts DataFrame columns", "Merges DataFrames"], explanation: "apply() applies a function along an axis of the DataFrame, enabling custom operations on rows or columns." },
                        { q: "What is a window function in SQL?", a: "Function that performs calculations across related rows", options: ["Function for GUI windows", "Function that performs calculations across related rows", "Function for time windows", "Database window management"], explanation: "Window functions perform calculations across a set of table rows related to the current row, without grouping rows into a single output row." },
                        { q: "What is the difference between append() and extend() in Python?", a: "append() adds single element, extend() adds multiple elements", options: ["append() is faster", "append() adds single element, extend() adds multiple elements", "extend() is newer", "No practical difference"], explanation: "append() adds a single element to the end of a list, while extend() adds multiple elements from an iterable." },
                        { q: "What is a subquery in SQL?", a: "Query nested inside another query", options: ["Part of main query", "Query nested inside another query", "Query below main query", "Substitute query"], explanation: "A subquery is a query nested inside another SQL query, used to provide values for the main query's conditions or calculations." },
                        { q: "What is vectorization in pandas?", a: "Operations applied to entire arrays at once, much faster than loops", options: ["Converting data to vectors", "Operations applied to entire arrays at once, much faster than loops", "A type of data visualization", "Memory optimization technique"], explanation: "Vectorization applies operations to entire arrays simultaneously using optimized C code, providing significant performance improvements over Python loops." },
                        { q: "What is a Common Table Expression (CTE) in SQL?", a: "Named temporary result set within a query", options: ["Common table format", "Named temporary result set within a query", "Shared table expression", "Table expression standard"], explanation: "A CTE is a named temporary result set that exists within the scope of a single query and can be referenced multiple times." },
                        { q: "What is the Global Interpreter Lock (GIL) in Python?", a: "Mutex that prevents multiple threads from executing Python code simultaneously", options: ["Global internet lock", "Mutex that prevents multiple threads from executing Python code simultaneously", "Global import lock", "General interface lock"], explanation: "The GIL is a mutex that protects access to Python objects, preventing multiple threads from executing Python bytecodes simultaneously." },
                        { q: "What is the difference between RANK() and ROW_NUMBER() in SQL?", a: "RANK() handles ties with gaps, ROW_NUMBER() assigns unique numbers", options: ["RANK() is faster", "RANK() handles ties with gaps, ROW_NUMBER() assigns unique numbers", "ROW_NUMBER() handles ties better", "No practical difference"], explanation: "RANK() assigns the same rank to tied values and skips subsequent ranks, while ROW_NUMBER() assigns unique sequential numbers regardless of ties." },
                        { q: "What is pandas groupby()?", a: "Groups DataFrame by one or more columns for aggregation", options: ["Groups files by type", "Groups DataFrame by one or more columns for aggregation", "Groups data visually", "Groups related operations"], explanation: "groupby() splits data into groups based on column values, allowing aggregate operations to be performed on each group separately." },
                        { q: "What is an index in SQL databases?", a: "Data structure that improves query performance", options: ["Table of contents", "Data structure that improves query performance", "Index finger pointer", "Database catalog"], explanation: "An index is a data structure that improves the speed of data retrieval operations by creating shortcuts to table rows." },
                        { q: "What is a generator in Python?", a: "Function that yields values one at a time, memory efficient", options: ["Power generator", "Function that yields values one at a time, memory efficient", "Code generator tool", "Random value generator"], explanation: "Generators are functions that yield values one at a time using the yield keyword, providing memory-efficient iteration over large datasets." },
                        { q: "What is a materialized view in SQL?", a: "Stored query result that can be refreshed", options: ["Physical database view", "Stored query result that can be refreshed", "Concrete view implementation", "Visible database view"], explanation: "A materialized view stores the result of a query physically and can be refreshed periodically to reflect changes in underlying tables." },
                        { q: "What is the difference between deep and shallow copy in Python?", a: "Deep copy creates independent copy, shallow copy shares references", options: ["Deep copy goes deeper", "Deep copy creates independent copy, shallow copy shares references", "Shallow copy is faster", "No practical difference"], explanation: "Shallow copy creates a new object but references to nested objects are shared, while deep copy creates completely independent copies of all nested objects." },
                        { q: "What is a stored procedure in SQL?", a: "Precompiled SQL code stored in database", options: ["Stored query procedure", "Precompiled SQL code stored in database", "Procedure for storing data", "Database storage method"], explanation: "A stored procedure is a prepared SQL code that can be saved and reused, executed on the database server for better performance and security." }
                    ],
                    3: [
                        { q: "How would you optimize a slow SQL query with multiple JOINs?", a: "Add indexes, use appropriate join types, analyze execution plan", options: ["Use more WHERE clauses", "Add indexes, use appropriate join types, analyze execution plan", "Always use LEFT JOINs", "Avoid using indexes"], explanation: "Query optimization involves analyzing execution plans, adding appropriate indexes on join columns, choosing optimal join types, and structuring queries efficiently." },
                        { q: "What is database sharding and when would you use it?", a: "Horizontal partitioning across multiple databases for scalability", options: ["Breaking databases into pieces", "Horizontal partitioning across multiple databases for scalability", "Database backup strategy", "Data encryption method"], explanation: "Sharding distributes data across multiple databases to handle large datasets and high traffic loads that exceed single database capacity." },
                        { q: "How do you handle race conditions in Python threading?", a: "Use locks, semaphores, or thread-safe data structures", options: ["Ignore race conditions", "Use locks, semaphores, or thread-safe data structures", "Use faster computers", "Race conditions don't exist"], explanation: "Race conditions are prevented using synchronization primitives like locks, semaphores, or atomic operations to ensure thread-safe access to shared resources." },
                        { q: "What is database indexing strategy for complex queries?", a: "Composite indexes, covering indexes, query pattern analysis", options: ["Index everything", "Composite indexes, covering indexes, query pattern analysis", "No indexing needed", "Single column indexes only"], explanation: "Effective indexing strategies involve creating composite indexes for multi-column queries, covering indexes to avoid table lookups, and analyzing query patterns." },
                        { q: "How do you implement efficient pagination in SQL?", a: "Use OFFSET/LIMIT with proper indexing or cursor-based pagination", options: ["Load all data", "Use OFFSET/LIMIT with proper indexing or cursor-based pagination", "Pagination is not needed", "Use random sampling"], explanation: "Efficient pagination uses OFFSET/LIMIT with proper indexing for small offsets, or cursor-based pagination for better performance with large offsets." },
                        { q: "What is the difference between multiprocessing and multithreading in Python?", a: "Multiprocessing uses separate processes, multithreading shares memory", options: ["Multiprocessing is faster", "Multiprocessing uses separate processes, multithreading shares memory", "Multithreading is newer", "No practical difference"], explanation: "Multiprocessing creates separate processes with independent memory, bypassing GIL, while multithreading shares memory but is limited by GIL for CPU-bound tasks." },
                        { q: "How do you design a database schema for high performance?", a: "Normalization balance, indexing strategy, partitioning, query patterns", options: ["Use one big table", "Normalization balance, indexing strategy, partitioning, query patterns", "Copy existing schemas", "Performance doesn't matter"], explanation: "High-performance schema design balances normalization with denormalization, strategic indexing, partitioning for large tables, and optimization for common query patterns." },
                        { q: "What is metaprogramming in Python?", a: "Writing code that manipulates code, using decorators, metaclasses", options: ["Programming metadata", "Writing code that manipulates code, using decorators, metaclasses", "Meta-analysis programming", "Programming about programming"], explanation: "Metaprogramming involves writing code that manipulates or generates other code, using features like decorators, metaclasses, and dynamic attribute access." },
                        { q: "How do you handle database transactions and ACID properties?", a: "Use BEGIN/COMMIT/ROLLBACK, ensure Atomicity, Consistency, Isolation, Durability", options: ["Transactions are automatic", "Use BEGIN/COMMIT/ROLLBACK, ensure Atomicity, Consistency, Isolation, Durability", "ACID is not important", "Handle manually"], explanation: "Database transactions ensure ACID properties through proper transaction boundaries, isolation levels, and rollback mechanisms for data integrity." },
                        { q: "What is async/await in Python and when to use it?", a: "Asynchronous programming for I/O-bound operations, non-blocking code", options: ["Advanced synchronization", "Asynchronous programming for I/O-bound operations, non-blocking code", "Automatic waiting mechanism", "Sync/wait alternative"], explanation: "Async/await enables asynchronous programming for I/O-bound operations, allowing other code to run while waiting for I/O operations to complete." },
                        { q: "How do you implement database connection pooling?", a: "Reuse connections, manage pool size, handle connection lifecycle", options: ["Create new connections always", "Reuse connections, manage pool size, handle connection lifecycle", "Pool connections randomly", "Connection pooling is automatic"], explanation: "Connection pooling reuses database connections to reduce overhead, managing pool size limits and connection lifecycle for optimal performance." },
                        { q: "What is the difference between SQL and NoSQL query optimization?", a: "SQL uses indexes and joins, NoSQL uses data modeling and denormalization", options: ["NoSQL is always faster", "SQL uses indexes and joins, NoSQL uses data modeling and denormalization", "SQL is always better", "No optimization differences"], explanation: "SQL optimization focuses on indexing and join strategies, while NoSQL optimization emphasizes data modeling, denormalization, and understanding specific database characteristics." },
                        { q: "How do you handle memory management in large pandas operations?", a: "Chunking data, efficient dtypes, memory profiling, garbage collection", options: ["Use more RAM", "Chunking data, efficient dtypes, memory profiling, garbage collection", "Memory management is automatic", "Ignore memory issues"], explanation: "Large pandas operations require chunking data into smaller pieces, using efficient data types, monitoring memory usage, and explicit garbage collection." },
                        { q: "What is database replication and how does it work?", a: "Copying data across multiple database servers for availability and performance", options: ["Duplicate database creation", "Copying data across multiple database servers for availability and performance", "Database backup process", "Data replication tool"], explanation: "Database replication maintains copies of data across multiple servers using master-slave or master-master configurations for high availability and read scalability." },
                        { q: "How do you implement custom data structures in Python?", a: "Use classes with special methods (__init__, __len__, __getitem__, etc.)", options: ["Import from libraries only", "Use classes with special methods (__init__, __len__, __getitem__, etc.)", "Custom structures not possible", "Use built-in types only"], explanation: "Custom data structures are implemented using classes with special methods (dunder methods) that define behavior for standard operations like indexing, iteration, and comparison." },
                        { q: "What are the considerations for SQL query performance tuning?", a: "Execution plans, indexing, query structure, statistics, caching", options: ["Query tuning is automatic", "Execution plans, indexing, query structure, statistics, caching", "Just add more indexes", "Performance doesn't matter"], explanation: "SQL performance tuning involves analyzing execution plans, optimizing indexes, restructuring queries, maintaining statistics, and leveraging caching mechanisms." }
                    ]
                },
                production: {
                    1: [
                        { q: "What is model serving in ML production?", a: "Making trained models available for real-time predictions", options: ["Training models on servers", "Making trained models available for real-time predictions", "Storing models in databases", "Validating model accuracy"], explanation: "Model serving is the process of deploying trained ML models to production environments where they can receive input data and return predictions in real-time." },
                        { q: "What is the difference between batch and real-time inference?", a: "Batch processes many predictions at once, real-time processes individual requests immediately", options: ["No practical difference", "Batch processes many predictions at once, real-time processes individual requests immediately", "Batch is always faster", "Real-time is more accurate"], explanation: "Batch inference processes large volumes of data periodically, while real-time inference provides immediate responses to individual prediction requests." },
                        { q: "What is a REST API in the context of ML models?", a: "HTTP interface for sending data to models and receiving predictions", options: ["A type of machine learning algorithm", "HTTP interface for sending data to models and receiving predictions", "A database for storing models", "A training framework"], explanation: "REST APIs provide a standardized HTTP interface for applications to send input data to ML models and receive predictions back." },
                        { q: "What is model deployment?", a: "Making trained models available in production environments", options: ["Training models", "Making trained models available in production environments", "Model testing", "Data preprocessing"], explanation: "Model deployment involves taking a trained model and making it available in a production environment to serve predictions to applications or users." },
                        { q: "What is containerization in ML deployment?", a: "Packaging models with dependencies in portable containers", options: ["Storing models in boxes", "Packaging models with dependencies in portable containers", "Container ship transportation", "Model compression"], explanation: "Containerization packages ML models with their runtime dependencies and configurations into portable containers for consistent deployment." },
                        { q: "What is load balancing for ML models?", a: "Distributing inference requests across multiple model instances", options: ["Balancing model weights", "Distributing inference requests across multiple model instances", "Load testing models", "Balancing training data"], explanation: "Load balancing distributes incoming prediction requests across multiple model instances to handle high traffic and ensure availability." },
                        { q: "What is model latency?", a: "Time taken to return a prediction", options: ["Model delay", "Time taken to return a prediction", "Model waiting time", "Prediction accuracy"], explanation: "Model latency is the time elapsed from when a request is made until the prediction is returned to the client." },
                        { q: "What is throughput in ML systems?", a: "Number of predictions processed per unit time", options: ["Data flow rate", "Number of predictions processed per unit time", "System capacity", "Processing speed"], explanation: "Throughput measures how many inference requests or predictions a system can process within a given time period." },
                        { q: "What is horizontal scaling?", a: "Adding more servers to handle increased load", options: ["Scaling in horizontal direction", "Adding more servers to handle increased load", "Increasing server width", "Horizontal data distribution"], explanation: "Horizontal scaling increases capacity by adding more servers or instances rather than upgrading existing hardware." },
                        { q: "What is vertical scaling?", a: "Upgrading existing server hardware for better performance", options: ["Scaling in vertical direction", "Upgrading existing server hardware for better performance", "Increasing server height", "Vertical data storage"], explanation: "Vertical scaling increases capacity by upgrading the hardware (CPU, RAM, storage) of existing servers." },
                        { q: "What is caching in ML systems?", a: "Storing frequently requested predictions to reduce computation", options: ["Hiding models", "Storing frequently requested predictions to reduce computation", "Cash payment system", "Model storage"], explanation: "Caching stores frequently requested predictions or intermediate results to reduce computation time for repeated requests." },
                        { q: "What is a health check in model deployment?", a: "Monitoring endpoint to verify model is functioning", options: ["Medical checkup for models", "Monitoring endpoint to verify model is functioning", "Model accuracy check", "Health insurance for models"], explanation: "Health checks are monitoring endpoints that verify whether deployed models are running and responding correctly." },
                        { q: "What is graceful degradation?", a: "System continues functioning with reduced capability during failures", options: ["Elegant system shutdown", "System continues functioning with reduced capability during failures", "Gradual performance improvement", "Graceful error messages"], explanation: "Graceful degradation ensures systems continue to operate with reduced functionality when components fail, rather than complete failure." },
                        { q: "What is circuit breaker pattern?", a: "Prevents cascading failures by stopping requests to failing services", options: ["Electrical circuit protection", "Prevents cascading failures by stopping requests to failing services", "Breaking model circuits", "Pattern recognition circuit"], explanation: "Circuit breaker pattern stops sending requests to failing services temporarily to prevent cascading failures and allow recovery time." },
                        { q: "What is model endpoint?", a: "URL or interface where model accepts requests", options: ["End of model training", "URL or interface where model accepts requests", "Final model layer", "Model termination point"], explanation: "A model endpoint is the accessible URL or interface where applications can send data and receive predictions from deployed models." },
                        { q: "What is auto-scaling?", a: "Automatically adjusting resources based on demand", options: ["Automatic model scaling", "Automatically adjusting resources based on demand", "Self-scaling models", "Automated scaling tools"], explanation: "Auto-scaling automatically increases or decreases computational resources based on current demand and predefined metrics." },
                        { q: "What is zero-downtime deployment?", a: "Updating systems without service interruption", options: ["Deployment with no time", "Updating systems without service interruption", "Instant deployment", "No-cost deployment"], explanation: "Zero-downtime deployment updates applications or models without interrupting service availability to users." }
                    ],
                    2: [
                        { q: "What is A/B testing for machine learning models?", a: "Comparing performance of different models with real user traffic", options: ["Testing models with A and B datasets", "Comparing performance of different models with real user traffic", "Using two different algorithms", "Testing on weekdays vs weekends"], explanation: "A/B testing splits real user traffic between different model versions to compare their performance and business impact in production." },
                        { q: "What metrics should you monitor for ML models in production?", a: "Accuracy, latency, throughput, data drift, and business metrics", options: ["Only accuracy", "Only response time", "Accuracy, latency, throughput, data drift, and business metrics", "Only error rates"], explanation: "Production ML monitoring requires tracking technical metrics (accuracy, latency), operational metrics (throughput, errors), and business impact metrics." },
                        { q: "What is blue-green deployment for ML models?", a: "Maintaining two identical environments to enable instant switching", options: ["Using blue and green colored interfaces", "Maintaining two identical environments to enable instant switching", "A type of model training", "Color-coding different features"], explanation: "Blue-green deployment maintains two identical production environments, allowing instant switching between model versions with zero downtime." },
                        { q: "What is canary deployment?", a: "Gradual rollout to subset of users while monitoring performance", options: ["Deployment with canary birds", "Gradual rollout to subset of users while monitoring performance", "Yellow-colored deployment", "Emergency deployment method"], explanation: "Canary deployment gradually routes a small percentage of traffic to new model versions while monitoring performance before full rollout." },
                        { q: "What is shadow mode deployment?", a: "Running new model alongside production without affecting users", options: ["Deploying in darkness", "Running new model alongside production without affecting users", "Hidden deployment method", "Shadow testing approach"], explanation: "Shadow mode runs new models parallel to production models to compare performance without affecting user experience." },
                        { q: "What is feature flagging?", a: "Controlling feature rollout through configuration switches", options: ["Marking important features", "Controlling feature rollout through configuration switches", "Flag-based feature selection", "Feature identification system"], explanation: "Feature flags allow controlled rollout of new features or model versions through configuration switches without code deployment." },
                        { q: "What is rollback strategy?", a: "Plan for reverting to previous version when issues occur", options: ["Rolling back data", "Plan for reverting to previous version when issues occur", "Backward rolling deployment", "Roll-back testing"], explanation: "Rollback strategy defines how to quickly revert to previous model versions when performance issues or errors are detected." },
                        { q: "What is model registry?", a: "Centralized repository for storing and versioning models", options: ["Model registration office", "Centralized repository for storing and versioning models", "Registry of model users", "Model documentation system"], explanation: "Model registry provides centralized storage, versioning, and metadata management for machine learning models across their lifecycle." },
                        { q: "What is infrastructure as code?", a: "Managing infrastructure through code and version control", options: ["Code-based infrastructure", "Managing infrastructure through code and version control", "Infrastructure programming", "Coded infrastructure setup"], explanation: "Infrastructure as code manages and provisions infrastructure through machine-readable definition files rather than manual processes." },
                        { q: "What is observability in ML systems?", a: "Comprehensive monitoring through metrics, logs, and traces", options: ["System visibility", "Comprehensive monitoring through metrics, logs, and traces", "Observable system behavior", "Observation-based monitoring"], explanation: "Observability provides deep insight into system behavior through the combination of metrics, structured logs, and distributed traces." },
                        { q: "What is data pipeline monitoring?", a: "Tracking data quality and flow through processing stages", options: ["Pipeline observation", "Tracking data quality and flow through processing stages", "Data pipe monitoring", "Pipeline performance tracking"], explanation: "Data pipeline monitoring tracks data quality, processing times, and potential issues as data flows through various transformation stages." },
                        { q: "What is model drift detection?", a: "Identifying when model performance degrades over time", options: ["Model movement detection", "Identifying when model performance degrades over time", "Drift pattern recognition", "Model shifting analysis"], explanation: "Model drift detection identifies when model performance degrades due to changes in data patterns or underlying relationships." },
                        { q: "What is alerting strategy?", a: "System for notifying teams of issues based on defined thresholds", options: ["Alert generation", "System for notifying teams of issues based on defined thresholds", "Warning system setup", "Alert management approach"], explanation: "Alerting strategy defines when, how, and whom to notify when system metrics exceed defined thresholds or anomalies are detected." },
                        { q: "What is chaos engineering?", a: "Testing system resilience by intentionally introducing failures", options: ["Chaotic system design", "Testing system resilience by intentionally introducing failures", "Random engineering approach", "Chaos theory application"], explanation: "Chaos engineering tests system resilience by deliberately introducing failures to identify weaknesses and improve fault tolerance." },
                        { q: "What is disaster recovery?", a: "Plan for restoring services after major system failures", options: ["Disaster prevention", "Plan for restoring services after major system failures", "Recovery from disasters", "Disaster management strategy"], explanation: "Disaster recovery outlines procedures for quickly restoring critical services and data after major system failures or catastrophic events." },
                        { q: "What is service mesh?", a: "Infrastructure layer for managing service-to-service communication", options: ["Mesh network service", "Infrastructure layer for managing service-to-service communication", "Service networking mesh", "Mesh-based service design"], explanation: "Service mesh provides infrastructure layer for managing, securing, and monitoring communication between microservices." }
                    ],
                    3: [
                        { q: "How would you handle model performance degradation in production?", a: "Implement automated monitoring, alerts, rollback mechanisms, and retraining pipelines", options: ["Just retrain the model", "Implement automated monitoring, alerts, rollback mechanisms, and retraining pipelines", "Switch to a different algorithm", "Increase server capacity"], explanation: "Handling degradation requires comprehensive monitoring systems, automated alerts, quick rollback capabilities, and systematic retraining processes." },
                        { q: "What are the key considerations for ML model scalability?", a: "Load balancing, caching, horizontal scaling, and resource optimization", options: ["Just add more servers", "Load balancing, caching, horizontal scaling, and resource optimization", "Use bigger models", "Increase memory only"], explanation: "ML scalability requires load balancing for traffic distribution, caching for common predictions, horizontal scaling capabilities, and optimized resource utilization." },
                        { q: "How do you implement multi-model serving architecture?", a: "Model orchestration, resource isolation, routing logic, and performance optimization", options: ["Deploy all models together", "Model orchestration, resource isolation, routing logic, and performance optimization", "Use single model endpoint", "Random model selection"], explanation: "Multi-model serving requires orchestration systems, resource isolation between models, intelligent routing, and performance optimization strategies." },
                        { q: "What is the difference between synchronous and asynchronous inference?", a: "Synchronous blocks until response, asynchronous allows concurrent processing", options: ["Synchronous is faster", "Synchronous blocks until response, asynchronous allows concurrent processing", "Asynchronous is more accurate", "No practical difference"], explanation: "Synchronous inference blocks the client until response is ready, while asynchronous inference allows concurrent request processing and callback handling." },
                        { q: "How do you optimize model inference performance?", a: "Model optimization, batch processing, caching, hardware acceleration", options: ["Use faster computers", "Model optimization, batch processing, caching, hardware acceleration", "Optimize is not needed", "Just increase memory"], explanation: "Inference optimization involves model compression, batching requests, result caching, and leveraging specialized hardware like GPUs or TPUs." },
                        { q: "What are the security considerations for ML model deployment?", a: "Authentication, encryption, input validation, model protection, audit logging", options: ["Security is not important", "Authentication, encryption, input validation, model protection, audit logging", "Just use passwords", "Security slows performance"], explanation: "ML security requires API authentication, data encryption, input validation, model intellectual property protection, and comprehensive audit logging." },
                        { q: "How do you handle versioning in production ML systems?", a: "Semantic versioning, metadata tracking, compatibility testing, rollback capabilities", options: ["Version numbers don't matter", "Semantic versioning, metadata tracking, compatibility testing, rollback capabilities", "Use dates for versions", "Versioning is automatic"], explanation: "Production versioning requires semantic version schemes, comprehensive metadata, backward compatibility testing, and reliable rollback mechanisms." },
                        { q: "What is the role of feature stores in production?", a: "Centralized feature management, consistency, real-time serving, monitoring", options: ["Feature stores not needed", "Centralized feature management, consistency, real-time serving, monitoring", "Just for feature storage", "Only for training features"], explanation: "Feature stores ensure consistent features between training and serving, provide low-latency feature retrieval, and enable feature monitoring and governance." },
                        { q: "How do you implement model governance in production?", a: "Approval workflows, compliance tracking, audit trails, policy enforcement", options: ["Governance slows development", "Approval workflows, compliance tracking, audit trails, policy enforcement", "Just document everything", "Governance is optional"], explanation: "Model governance requires formal approval processes, compliance monitoring, detailed audit trails, and automated policy enforcement mechanisms." },
                        { q: "What are the challenges of real-time ML serving?", a: "Latency requirements, scalability, fault tolerance, data consistency", options: ["No challenges exist", "Latency requirements, scalability, fault tolerance, data consistency", "Just speed issues", "Only hardware limitations"], explanation: "Real-time serving faces strict latency requirements, high scalability demands, fault tolerance needs, and data consistency challenges." },
                        { q: "How do you design for high availability in ML systems?", a: "Redundancy, failover mechanisms, health monitoring, geographic distribution", options: ["High availability is automatic", "Redundancy, failover mechanisms, health monitoring, geographic distribution", "Just use good hardware", "Availability doesn't matter"], explanation: "High availability requires system redundancy, automatic failover, continuous health monitoring, and geographic distribution of services." },
                        { q: "What is edge deployment for ML models?", a: "Running models on local devices for reduced latency and privacy", options: ["Deploying at network edges", "Running models on local devices for reduced latency and privacy", "Edge case deployment", "Boundary model deployment"], explanation: "Edge deployment runs ML models on local devices or edge servers to reduce latency, improve privacy, and enable offline functionality." },
                        { q: "How do you handle model updates without service disruption?", a: "Rolling updates, traffic shifting, health checks, automated rollback", options: ["Stop service during updates", "Rolling updates, traffic shifting, health checks, automated rollback", "Update everything at once", "Updates always disrupt service"], explanation: "Seamless updates use rolling deployment strategies, gradual traffic shifting, continuous health monitoring, and automated rollback on failure." },
                        { q: "What is cost optimization in ML production?", a: "Resource right-sizing, auto-scaling, spot instances, model efficiency", options: ["Cost doesn't matter", "Resource right-sizing, auto-scaling, spot instances, model efficiency", "Always use cheapest options", "Cost optimization hurts performance"], explanation: "Cost optimization involves right-sizing resources, implementing auto-scaling, using spot instances, and improving model efficiency without sacrificing performance." },
                        { q: "How do you implement comprehensive ML system monitoring?", a: "Multi-layer monitoring, custom metrics, alerting, dashboards, SLA tracking", options: ["Monitoring is optional", "Multi-layer monitoring, custom metrics, alerting, dashboards, SLA tracking", "Just monitor errors", "Basic logging is enough"], explanation: "Comprehensive monitoring spans infrastructure, application, and business layers with custom metrics, intelligent alerting, visual dashboards, and SLA tracking." },
                        { q: "What are the compliance requirements for ML in production?", a: "Data privacy, model explainability, audit trails, regulatory adherence", options: ["Compliance is not needed", "Data privacy, model explainability, audit trails, regulatory adherence", "Just legal approval", "Compliance slows innovation"], explanation: "ML compliance requires data privacy protection, model explainability capabilities, comprehensive audit trails, and adherence to industry regulations." }
                    ]
                },
                data_eng: {
                    1: [
                        { q: "What is ETL in data engineering?", a: "Extract, Transform, Load - process for moving data between systems", options: ["Error, Test, Log", "Extract, Transform, Load - process for moving data between systems", "Evaluate, Train, Learn", "Export, Transfer, Link"], explanation: "ETL is the process of extracting data from sources, transforming it into the desired format, and loading it into target systems like data warehouses." },
                        { q: "What is the difference between structured and unstructured data?", a: "Structured data has predefined schema, unstructured data doesn't", options: ["No practical difference", "Structured data has predefined schema, unstructured data doesn't", "Structured data is always smaller", "Unstructured data is faster to process"], explanation: "Structured data follows a predefined schema (like databases), while unstructured data (text, images, videos) doesn't have a fixed format." },
                        { q: "What is a data pipeline?", a: "Automated workflow for moving and transforming data", options: ["A type of database", "Automated workflow for moving and transforming data", "A visualization tool", "A machine learning algorithm"], explanation: "Data pipelines are automated workflows that move data from sources through various transformation steps to destinations." },
                        { q: "What is data quality?", a: "Measure of data's fitness for intended use", options: ["High-quality data storage", "Measure of data's fitness for intended use", "Premium data services", "Quality assurance for data"], explanation: "Data quality measures how well data meets requirements for accuracy, completeness, consistency, timeliness, and validity." },
                        { q: "What is data lineage?", a: "Tracking data's origin, movement, and transformation", options: ["Data family tree", "Tracking data's origin, movement, and transformation", "Linear data arrangement", "Data inheritance system"], explanation: "Data lineage tracks the complete journey of data from its origin through all transformations and movements." },
                        { q: "What is batch processing?", a: "Processing large volumes of data in scheduled chunks", options: ["Processing in batches only", "Processing large volumes of data in scheduled chunks", "Small group processing", "Batch file processing"], explanation: "Batch processing handles large volumes of data in discrete chunks at scheduled intervals rather than continuously." },
                        { q: "What is stream processing?", a: "Processing data in real-time as it arrives", options: ["Processing streaming video", "Processing data in real-time as it arrives", "Water stream processing", "Streaming media processing"], explanation: "Stream processing analyzes and transforms data continuously as it flows through the system in real-time." },
                        { q: "What is data validation?", a: "Checking data meets quality and business requirements", options: ["Validating data storage", "Checking data meets quality and business requirements", "Data approval process", "Validation certificate for data"], explanation: "Data validation ensures data meets defined quality standards, business rules, and schema requirements." },
                        { q: "What is data transformation?", a: "Converting data from one format or structure to another", options: ["Data shape changing", "Converting data from one format or structure to another", "Data movement process", "Transforming data appearance"], explanation: "Data transformation converts data from source format to target format, including cleaning, aggregation, and restructuring." },
                        { q: "What is a data warehouse?", a: "Centralized repository for storing processed data", options: ["Storage warehouse for data", "Centralized repository for storing processed data", "Data storage building", "Warehouse management system"], explanation: "Data warehouses store processed, structured data from multiple sources for reporting and analytics." },
                        { q: "What is data integration?", a: "Combining data from multiple sources into unified view", options: ["Integrating data systems", "Combining data from multiple sources into unified view", "Data system integration", "Integrated data management"], explanation: "Data integration combines data from disparate sources to provide users with unified access and view." },
                        { q: "What is data governance?", a: "Framework for managing data assets and ensuring quality", options: ["Data government control", "Framework for managing data assets and ensuring quality", "Governing data usage", "Data policy governance"], explanation: "Data governance establishes policies, procedures, and standards for managing data as an organizational asset." },
                        { q: "What is a schema?", a: "Structure that defines organization of data", options: ["Data scheme", "Structure that defines organization of data", "Schema diagram", "Schematic for data"], explanation: "A schema defines the logical structure of data, including tables, fields, relationships, and constraints." },
                        { q: "What is data modeling?", a: "Creating abstract representation of data structures", options: ["Modeling with data", "Creating abstract representation of data structures", "Data visualization modeling", "Mathematical data models"], explanation: "Data modeling creates conceptual, logical, and physical representations of data structures and relationships." },
                        { q: "What is metadata?", a: "Data that describes other data", options: ["Meta-level data", "Data that describes other data", "Additional data", "Data beyond data"], explanation: "Metadata provides information about data characteristics, structure, quality, and context." },
                        { q: "What is data partitioning?", a: "Dividing data into smaller, manageable segments", options: ["Creating data partitions", "Dividing data into smaller, manageable segments", "Partitioning data storage", "Data division process"], explanation: "Data partitioning divides large datasets into smaller segments based on criteria like date, region, or hash values." },
                        { q: "What is data archiving?", a: "Moving old data to long-term storage", options: ["Archiving data files", "Moving old data to long-term storage", "Data backup process", "Creating data archives"], explanation: "Data archiving moves infrequently accessed data to cost-effective, long-term storage while maintaining accessibility." }
                    ],
                    2: [
                        { q: "What is the difference between data lake and data warehouse?", a: "Data lakes store raw data in native format, warehouses store structured processed data", options: ["No difference", "Data lakes store raw data in native format, warehouses store structured processed data", "Data lakes are always smaller", "Warehouses are always faster"], explanation: "Data lakes store raw data in its native format for flexibility, while data warehouses store structured, processed data optimized for analysis." },
                        { q: "What is Apache Spark used for in data engineering?", a: "Large-scale data processing and analytics", options: ["Database storage", "Large-scale data processing and analytics", "Data visualization", "Model training only"], explanation: "Apache Spark is a distributed computing framework for large-scale data processing, analytics, and machine learning across clusters." },
                        { q: "What is data partitioning and why is it important?", a: "Dividing data into smaller chunks for better performance and management", options: ["Copying data multiple times", "Dividing data into smaller chunks for better performance and management", "Encrypting sensitive data", "Compressing data files"], explanation: "Data partitioning divides large datasets into smaller, manageable chunks based on criteria like date or region, improving query performance and parallel processing." },
                        { q: "What is Apache Kafka?", a: "Distributed streaming platform for real-time data feeds", options: ["Database system", "Distributed streaming platform for real-time data feeds", "Data visualization tool", "Machine learning framework"], explanation: "Apache Kafka is a distributed streaming platform that handles high-volume, real-time data feeds between applications." },
                        { q: "What is change data capture (CDC)?", a: "Identifying and capturing changes in source data", options: ["Capturing data changes manually", "Identifying and capturing changes in source data", "Change detection algorithm", "Data change documentation"], explanation: "CDC identifies and captures data changes in source systems to propagate incremental updates to downstream systems." },
                        { q: "What is data replication?", a: "Creating copies of data across multiple systems", options: ["Duplicating data storage", "Creating copies of data across multiple systems", "Data copying process", "Replicating data formats"], explanation: "Data replication maintains synchronized copies of data across multiple systems for availability, performance, and disaster recovery." },
                        { q: "What is OLTP vs OLAP?", a: "OLTP for transactions, OLAP for analytics", options: ["OLTP is faster", "OLTP for transactions, OLAP for analytics", "OLAP is newer", "No practical difference"], explanation: "OLTP (Online Transaction Processing) handles day-to-day transactions, while OLAP (Online Analytical Processing) supports complex analytical queries." },
                        { q: "What is data denormalization?", a: "Combining normalized tables to improve query performance", options: ["Making data abnormal", "Combining normalized tables to improve query performance", "Removing data normalization", "Denormalizing data values"], explanation: "Data denormalization strategically introduces redundancy to improve query performance by reducing joins in analytical workloads." },
                        { q: "What is horizontal vs vertical partitioning?", a: "Horizontal splits by rows, vertical splits by columns", options: ["Horizontal is faster", "Horizontal splits by rows, vertical splits by columns", "Vertical is more secure", "No practical difference"], explanation: "Horizontal partitioning divides tables by rows (like by date), while vertical partitioning divides by columns (like separating frequently vs rarely used fields)." },
                        { q: "What is data compression?", a: "Reducing storage space by encoding data efficiently", options: ["Compressing data files", "Reducing storage space by encoding data efficiently", "Making data smaller", "Data size reduction"], explanation: "Data compression reduces storage requirements and transfer times by encoding data more efficiently using various algorithms." },
                        { q: "What is eventual consistency?", a: "System becomes consistent over time without immediate consistency", options: ["Consistent eventually", "System becomes consistent over time without immediate consistency", "Final consistency state", "Consistency that comes later"], explanation: "Eventual consistency guarantees that replicated data will become consistent across all nodes eventually, though not immediately." },
                        { q: "What is data sharding?", a: "Horizontal partitioning across multiple databases", options: ["Breaking data into shards", "Horizontal partitioning across multiple databases", "Shard-based storage", "Data fragmentation"], explanation: "Data sharding distributes data across multiple database instances to improve scalability and performance." },
                        { q: "What is a message queue?", a: "System for asynchronous communication between applications", options: ["Queue for messages", "System for asynchronous communication between applications", "Message waiting line", "Queue-based messaging"], explanation: "Message queues enable asynchronous communication by allowing applications to send and receive messages without direct connection." },
                        { q: "What is idempotency in data processing?", a: "Operation produces same result when executed multiple times", options: ["Identical processing", "Operation produces same result when executed multiple times", "Processing power", "Potent data operations"], explanation: "Idempotent operations produce the same result whether executed once or multiple times, crucial for reliable data processing." },
                        { q: "What is backpressure?", a: "Mechanism to handle when consumers can't keep up with producers", options: ["Pressure from behind", "Mechanism to handle when consumers can't keep up with producers", "Backward processing pressure", "Pressure relief system"], explanation: "Backpressure manages flow control when data consumers cannot process data as fast as producers generate it." },
                        { q: "What is data serialization?", a: "Converting data structures into storable format", options: ["Making data serial", "Converting data structures into storable format", "Serial data processing", "Data sequence creation"], explanation: "Data serialization converts complex data structures into formats that can be stored or transmitted and later reconstructed." }
                    ],
                    3: [
                        { q: "How would you design a real-time streaming data pipeline?", a: "Use stream processing frameworks like Kafka, implement exactly-once semantics, handle backpressure", options: ["Just use batch processing", "Use stream processing frameworks like Kafka, implement exactly-once semantics, handle backpressure", "Store everything in memory", "Process data manually"], explanation: "Real-time pipelines require stream processing tools (Kafka, Spark Streaming), exactly-once processing guarantees, backpressure handling, and fault tolerance." },
                        { q: "What are the key challenges in data quality for ML?", a: "Completeness, accuracy, consistency, timeliness, and validity across distributed systems", options: ["Just checking for nulls", "Completeness, accuracy, consistency, timeliness, and validity across distributed systems", "Only file format validation", "Manual inspection only"], explanation: "ML data quality requires ensuring completeness, accuracy, consistency, timeliness, and validity across complex distributed systems and multiple data sources." },
                        { q: "How do you handle schema evolution in data pipelines?", a: "Version schemas, backward compatibility, gradual migration, schema registry", options: ["Schemas never change", "Version schemas, backward compatibility, gradual migration, schema registry", "Always break compatibility", "Manual schema updates"], explanation: "Schema evolution requires versioning, maintaining backward compatibility, implementing gradual migrations, and using schema registries for governance." },
                        { q: "What is the Lambda architecture?", a: "Architecture combining batch and stream processing for comprehensive analytics", options: ["Greek letter architecture", "Architecture combining batch and stream processing for comprehensive analytics", "Lambda function architecture", "Serverless data architecture"], explanation: "Lambda architecture processes data through both batch layer (accuracy) and speed layer (low latency) to provide comprehensive real-time analytics." },
                        { q: "How do you implement data lineage tracking?", a: "Metadata capture, dependency graphs, automated discovery, visualization tools", options: ["Manual documentation", "Metadata capture, dependency graphs, automated discovery, visualization tools", "Lineage is not important", "Track manually"], explanation: "Data lineage tracking requires automated metadata capture, dependency graphing, discovery tools, and visualization platforms." },
                        { q: "What is the Kappa architecture?", a: "Stream-first architecture that processes all data as streams", options: ["Kappa fraternity architecture", "Stream-first architecture that processes all data as streams", "Greek architecture pattern", "Simplified lambda architecture"], explanation: "Kappa architecture treats all data as streams, using stream processing for both real-time and historical data analysis." },
                        { q: "How do you handle late-arriving data in streaming systems?", a: "Watermarks, windowing strategies, allowable lateness policies", options: ["Ignore late data", "Watermarks, windowing strategies, allowable lateness policies", "Always wait for all data", "Late data is not a problem"], explanation: "Late data handling requires watermark strategies, appropriate windowing, allowable lateness policies, and side output handling." },
                        { q: "What is data mesh architecture?", a: "Decentralized data architecture with domain ownership", options: ["Mesh network for data", "Decentralized data architecture with domain ownership", "Data networking mesh", "Mesh-based data storage"], explanation: "Data mesh treats data as a product with domain ownership, self-serve infrastructure, and federated governance." },
                        { q: "How do you implement exactly-once processing?", a: "Idempotent operations, transactional systems, deduplication, checkpointing", options: ["Process everything once", "Idempotent operations, transactional systems, deduplication, checkpointing", "Exactly-once is impossible", "Single processing guarantee"], explanation: "Exactly-once semantics require idempotent operations, transactional guarantees, deduplication mechanisms, and consistent checkpointing." },
                        { q: "What are the considerations for multi-cloud data strategy?", a: "Data sovereignty, vendor lock-in, latency, security, cost optimization", options: ["Use all clouds equally", "Data sovereignty, vendor lock-in, latency, security, cost optimization", "Multi-cloud is not needed", "Single cloud is better"], explanation: "Multi-cloud strategy must address data sovereignty, avoid vendor lock-in, optimize latency, ensure security, and manage costs." },
                        { q: "How do you design for data disaster recovery?", a: "Backup strategies, replication, failover procedures, testing protocols", options: ["Disasters don't affect data", "Backup strategies, replication, failover procedures, testing protocols", "Just backup everything", "Disaster recovery is automatic"], explanation: "Data disaster recovery requires comprehensive backup strategies, replication mechanisms, tested failover procedures, and regular recovery drills." },
                        { q: "What is data virtualization?", a: "Providing unified access to data without physical integration", options: ["Virtual data storage", "Providing unified access to data without physical integration", "Virtualized data centers", "Data in virtual machines"], explanation: "Data virtualization creates logical data layer that provides unified access to distributed data sources without physical data movement." },
                        { q: "How do you optimize data pipeline performance?", a: "Parallel processing, caching, indexing, resource optimization, monitoring", options: ["Performance doesn't matter", "Parallel processing, caching, indexing, resource optimization, monitoring", "Just add more servers", "Optimization is automatic"], explanation: "Pipeline optimization requires parallel processing, strategic caching, appropriate indexing, resource tuning, and performance monitoring." },
                        { q: "What is zero-copy optimization?", a: "Minimizing data copying between memory and storage systems", options: ["Not copying any data", "Minimizing data copying between memory and storage systems", "Zero-cost data copying", "Copy-free data processing"], explanation: "Zero-copy optimization reduces data movement between system components, improving performance by minimizing memory copying operations." },
                        { q: "How do you handle data privacy and compliance in pipelines?", a: "Data masking, encryption, access controls, audit trails, privacy by design", options: ["Privacy is not important", "Data masking, encryption, access controls, audit trails, privacy by design", "Just encrypt everything", "Compliance slows pipelines"], explanation: "Data privacy requires masking sensitive data, encryption at rest/transit, granular access controls, comprehensive audit trails, and privacy-by-design principles." },
                        { q: "What is event sourcing?", a: "Storing all changes as sequence of events rather than current state", options: ["Sourcing from events", "Storing all changes as sequence of events rather than current state", "Event-based sourcing", "Source code for events"], explanation: "Event sourcing captures all changes as immutable events, allowing reconstruction of any past state and providing complete audit trail." }
                    ]
                },
                ethics: {
                    1: [
                        { q: "What is algorithmic bias in AI systems?", a: "Unfair treatment of certain groups due to biased training data or algorithms", options: ["Preference for certain algorithms", "Unfair treatment of certain groups due to biased training data or algorithms", "Faster processing for some data types", "Technical errors in code"], explanation: "Algorithmic bias occurs when AI systems systematically discriminate against certain groups, often due to biased training data or flawed algorithm design." },
                        { q: "What does 'explainable AI' (XAI) mean?", a: "AI systems that can provide clear explanations for their decisions", options: ["AI that speaks multiple languages", "AI systems that can provide clear explanations for their decisions", "AI that's easy to install", "AI with good documentation"], explanation: "Explainable AI refers to machine learning techniques and systems that can provide human-understandable explanations for their predictions and decisions." },
                        { q: "Why is data privacy important in AI development?", a: "To protect individual rights and prevent misuse of personal information", options: ["To reduce storage costs", "To protect individual rights and prevent misuse of personal information", "To make algorithms faster", "To simplify data collection"], explanation: "Data privacy protects individuals' personal information from unauthorized access and misuse, ensuring AI systems respect user rights and comply with regulations." },
                        { q: "What is informed consent in AI?", a: "Users understanding what data is collected and how it's used", options: ["Consent from informed people", "Users understanding what data is collected and how it's used", "Formal consent documents", "Legal consent requirements"], explanation: "Informed consent ensures users understand what data is being collected, how it will be used, and the potential risks before agreeing to participate." },
                        { q: "What is transparency in AI?", a: "Making AI decision processes understandable to users", options: ["Clear AI interfaces", "Making AI decision processes understandable to users", "Transparent AI hardware", "See-through AI systems"], explanation: "AI transparency involves making the decision-making processes and logic of AI systems understandable and accessible to users and stakeholders." },
                        { q: "What is accountability in AI?", a: "Clear responsibility for AI system decisions and outcomes", options: ["AI system accounting", "Clear responsibility for AI system decisions and outcomes", "Financial accountability", "Accountable AI development"], explanation: "AI accountability ensures there are clear lines of responsibility for AI system decisions, outcomes, and potential harms." },
                        { q: "What is human oversight in AI?", a: "Maintaining human control and review of AI decisions", options: ["Humans watching AI work", "Maintaining human control and review of AI decisions", "Human supervision of AI", "Oversight committee for AI"], explanation: "Human oversight ensures that humans retain meaningful control over AI systems and can intervene when necessary." },
                        { q: "What is the right to explanation?", a: "Individual's right to understand automated decisions affecting them", options: ["Right to explain AI", "Individual's right to understand automated decisions affecting them", "Explanation rights in AI", "Right to AI explanations"], explanation: "The right to explanation gives individuals the ability to understand and challenge automated decisions that significantly affect them." },
                        { q: "What is AI safety?", a: "Ensuring AI systems operate safely and don't cause harm", options: ["Safe AI storage", "Ensuring AI systems operate safely and don't cause harm", "AI security measures", "Safety protocols for AI"], explanation: "AI safety focuses on developing AI systems that operate reliably, predictably, and without causing unintended harm to humans or society." },
                        { q: "What is digital divide?", a: "Gap between those with and without access to digital technologies", options: ["Division of digital data", "Gap between those with and without access to digital technologies", "Digital separation", "Divide in digital systems"], explanation: "Digital divide refers to the gap between individuals, communities, or nations that have access to digital technologies and those that don't." },
                        { q: "What is responsible AI?", a: "Developing and deploying AI systems ethically and safely", options: ["AI with responsibilities", "Developing and deploying AI systems ethically and safely", "Responsible AI usage", "AI accountability measures"], explanation: "Responsible AI involves developing, deploying, and using AI systems in ways that are ethical, fair, transparent, and beneficial to society." },
                        { q: "What is AI governance?", a: "Frameworks and policies for managing AI development and deployment", options: ["Government control of AI", "Frameworks and policies for managing AI development and deployment", "AI management systems", "Governance by AI"], explanation: "AI governance encompasses the frameworks, policies, and institutions needed to guide the responsible development and deployment of AI technologies." },
                        { q: "What is value alignment in AI?", a: "Ensuring AI systems pursue goals aligned with human values", options: ["Aligning AI values", "Ensuring AI systems pursue goals aligned with human values", "Value-based AI alignment", "Alignment of AI values"], explanation: "Value alignment ensures that AI systems pursue objectives that are consistent with human values and societal goals." },
                        { q: "What is robustness in AI ethics?", a: "AI systems performing reliably across diverse conditions", options: ["Strong AI systems", "AI systems performing reliably across diverse conditions", "Robust AI architecture", "AI system strength"], explanation: "Robustness refers to AI systems maintaining reliable performance across diverse conditions, inputs, and environments." },
                        { q: "What is beneficence in AI?", a: "AI systems designed to benefit humanity and do good", options: ["Beneficial AI features", "AI systems designed to benefit humanity and do good", "AI system benefits", "Beneficiary AI systems"], explanation: "Beneficence in AI ethics means designing systems that actively promote human welfare and contribute positively to society." },
                        { q: "What is non-maleficence in AI?", a: "Ensuring AI systems do not cause harm", options: ["Non-harmful AI", "Ensuring AI systems do not cause harm", "AI without malice", "Preventing AI harm"], explanation: "Non-maleficence is the principle that AI systems should not cause harm to individuals or society, following the 'do no harm' principle." },
                        { q: "What is AI auditing?", a: "Systematic evaluation of AI systems for ethical compliance", options: ["Auditing AI finances", "Systematic evaluation of AI systems for ethical compliance", "AI system audits", "Auditing AI performance"], explanation: "AI auditing involves systematic evaluation of AI systems to assess their fairness, transparency, accountability, and compliance with ethical standards." }
                    ],
                    2: [
                        { q: "What is fairness in machine learning?", a: "Ensuring equal treatment and outcomes across different demographic groups", options: ["Using the same algorithm for everyone", "Ensuring equal treatment and outcomes across different demographic groups", "Having equal amounts of training data", "Using fair random sampling"], explanation: "ML fairness ensures that algorithms don't discriminate against protected groups and provide equitable outcomes across different demographics." },
                        { q: "What is differential privacy?", a: "Mathematical framework for quantifying and limiting privacy loss", options: ["Different privacy settings for different users", "Mathematical framework for quantifying and limiting privacy loss", "Separate databases for different data types", "Variable encryption levels"], explanation: "Differential privacy provides mathematical guarantees that individual privacy is protected even when statistical information is shared from datasets." },
                        { q: "What are the key principles of responsible AI?", a: "Fairness, accountability, transparency, and human oversight", options: ["Speed, accuracy, and efficiency only", "Fairness, accountability, transparency, and human oversight", "Profitability and market share", "Technical complexity and innovation"], explanation: "Responsible AI encompasses fairness in outcomes, accountability for decisions, transparency in operations, and maintaining meaningful human oversight." },
                        { q: "What is algorithmic accountability?", a: "Responsibility for decisions made by automated systems", options: ["Accounting for algorithms", "Responsibility for decisions made by automated systems", "Algorithm performance accountability", "Accountable algorithm design"], explanation: "Algorithmic accountability ensures there are mechanisms to hold developers and deployers responsible for automated decision-making systems." },
                        { q: "What is federated learning's privacy benefit?", a: "Training models without centralizing sensitive data", options: ["Federal privacy laws", "Training models without centralizing sensitive data", "Federated privacy controls", "Learning privacy federally"], explanation: "Federated learning enables collaborative model training while keeping sensitive data distributed, enhancing privacy protection." },
                        { q: "What is the right to be forgotten?", a: "Individual's right to have personal data deleted", options: ["Forgetting AI rights", "Individual's right to have personal data deleted", "Right to forget AI", "Forgotten rights in AI"], explanation: "The right to be forgotten allows individuals to request deletion of their personal data from systems, including AI training datasets." },
                        { q: "What is homomorphic encryption?", a: "Encryption that allows computation on encrypted data", options: ["Similar encryption methods", "Encryption that allows computation on encrypted data", "Home-based encryption", "Morphing encryption"], explanation: "Homomorphic encryption enables computations on encrypted data without decrypting it, preserving privacy during AI processing." },
                        { q: "What is bias amplification?", a: "AI systems magnifying existing societal biases", options: ["Amplifying system bias", "AI systems magnifying existing societal biases", "Bias sound amplification", "Amplified bias detection"], explanation: "Bias amplification occurs when AI systems learn from biased data and subsequently magnify those biases in their decisions." },
                        { q: "What is demographic parity?", a: "Equal positive outcome rates across demographic groups", options: ["Parity in demographics", "Equal positive outcome rates across demographic groups", "Demographic equality", "Population parity"], explanation: "Demographic parity requires that AI systems provide equal positive outcome rates across different demographic groups." },
                        { q: "What is individual fairness?", a: "Similar individuals should receive similar treatment", options: ["Personal fairness", "Similar individuals should receive similar treatment", "Individual treatment fairness", "Fair individual processing"], explanation: "Individual fairness ensures that similar individuals receive similar outcomes from AI systems, regardless of group membership." },
                        { q: "What is counterfactual fairness?", a: "Decisions would be same in counterfactual world without sensitive attributes", options: ["Opposite fairness", "Decisions would be same in counterfactual world without sensitive attributes", "Counter-fair decisions", "Factual counter-fairness"], explanation: "Counterfactual fairness requires that decisions would be the same in a counterfactual world where sensitive attributes were different." },
                        { q: "What is privacy-preserving ML?", a: "Machine learning techniques that protect individual privacy", options: ["Private ML models", "Machine learning techniques that protect individual privacy", "ML privacy settings", "Preserving ML privacy"], explanation: "Privacy-preserving ML uses techniques like differential privacy, federated learning, and secure computation to protect individual privacy." },
                        { q: "What is data minimization?", a: "Collecting only necessary data for specific purposes", options: ["Minimizing data size", "Collecting only necessary data for specific purposes", "Minimal data storage", "Data reduction techniques"], explanation: "Data minimization principle requires collecting and processing only the minimum data necessary for specific, legitimate purposes." },
                        { q: "What is purpose limitation?", a: "Using data only for originally specified purposes", options: ["Limited AI purposes", "Using data only for originally specified purposes", "Purpose-limited AI", "Limiting AI purposes"], explanation: "Purpose limitation ensures that personal data is used only for the specific purposes for which it was originally collected." },
                        { q: "What is consent management?", a: "Systems for obtaining and managing user consent", options: ["Managing AI consent", "Systems for obtaining and managing user consent", "Consent-based management", "Management consent systems"], explanation: "Consent management involves systems and processes for obtaining, recording, and managing user consent for data processing." },
                        { q: "What is ethical AI by design?", a: "Incorporating ethical considerations from the start of AI development", options: ["AI designed ethically", "Incorporating ethical considerations from the start of AI development", "Design ethics for AI", "Ethical AI design principles"], explanation: "Ethical AI by design embeds ethical considerations into every stage of AI development, from conception to deployment." }
                    ],
                    3: [
                        { q: "How would you detect and mitigate bias in a hiring AI system?", a: "Audit training data, test across demographics, implement bias metrics, and use bias-aware algorithms", options: ["Just use more data", "Audit training data, test across demographics, implement bias metrics, and use bias-aware algorithms", "Remove all demographic information", "Use only technical skills"], explanation: "Bias mitigation requires comprehensive auditing of training data, testing across demographic groups, implementing fairness metrics, and using bias-aware machine learning techniques." },
                        { q: "What are the ethical implications of deepfakes and synthetic media?", a: "Consent, misinformation, identity theft, and erosion of trust in authentic media", options: ["Just technical challenges", "Consent, misinformation, identity theft, and erosion of trust in authentic media", "Copyright issues only", "Storage and bandwidth costs"], explanation: "Deepfakes raise serious ethical concerns including consent violations, spread of misinformation, identity theft, and the broader erosion of trust in authentic media." },
                        { q: "How do you implement algorithmic impact assessments?", a: "Systematic evaluation of AI system effects on individuals and society", options: ["Impact assessments are not needed", "Systematic evaluation of AI system effects on individuals and society", "Only technical impact matters", "Impact assessment is automatic"], explanation: "Algorithmic impact assessments systematically evaluate potential effects of AI systems on individuals, communities, and society before deployment." },
                        { q: "What is the trolley problem in AI ethics?", a: "Dilemma about how AI should make moral decisions in harmful situations", options: ["Problem with AI trolleys", "Dilemma about how AI should make moral decisions in harmful situations", "Transportation AI problem", "Trolley scheduling problem"], explanation: "The trolley problem in AI explores how autonomous systems should make moral decisions when all available actions result in some harm." },
                        { q: "How do you ensure AI transparency in black box models?", a: "Post-hoc explanations, interpretable proxies, attention mechanisms, SHAP values", options: ["Black box models cannot be transparent", "Post-hoc explanations, interpretable proxies, attention mechanisms, SHAP values", "Only use white box models", "Transparency is not possible"], explanation: "Transparency in complex models requires post-hoc explanation techniques, interpretable proxy models, attention visualization, and explanation methods like SHAP." },
                        { q: "What is algorithmic recourse?", a: "Ability for individuals to change outcomes by modifying their attributes", options: ["Legal recourse for algorithms", "Ability for individuals to change outcomes by modifying their attributes", "Algorithm recovery methods", "Recourse against AI decisions"], explanation: "Algorithmic recourse ensures individuals can take actionable steps to change unfavorable automated decisions affecting them." },
                        { q: "How do you handle conflicting ethical principles in AI?", a: "Stakeholder engagement, ethical frameworks, contextual analysis, trade-off documentation", options: ["Choose the most important principle", "Stakeholder engagement, ethical frameworks, contextual analysis, trade-off documentation", "Ignore conflicts", "Conflicts don't exist"], explanation: "Ethical conflicts require stakeholder consultation, established frameworks, contextual analysis, and transparent documentation of trade-offs." },
                        { q: "What is value-sensitive design in AI?", a: "Design process that accounts for human values throughout development", options: ["Designing valuable AI", "Design process that accounts for human values throughout development", "Sensitive AI design", "Value-based AI pricing"], explanation: "Value-sensitive design systematically incorporates human values and ethical considerations throughout the AI development process." },
                        { q: "How do you implement continuous ethical monitoring?", a: "Ongoing assessment, feedback loops, stakeholder input, adaptive governance", options: ["Monitoring is not continuous", "Ongoing assessment, feedback loops, stakeholder input, adaptive governance", "One-time ethical review", "Monitoring is automatic"], explanation: "Continuous ethical monitoring requires ongoing assessment systems, feedback loops, regular stakeholder input, and adaptive governance structures." },
                        { q: "What is the precautionary principle in AI?", a: "Taking preventive action despite scientific uncertainty about risks", options: ["Being cautious about AI", "Taking preventive action despite scientific uncertainty about risks", "Precautionary AI measures", "Caution-based AI principles"], explanation: "The precautionary principle advocates for preventive measures against potentially harmful AI even when scientific evidence is incomplete." },
                        { q: "How do you address AI's impact on employment?", a: "Reskilling programs, gradual automation, social safety nets, human-AI collaboration", options: ["AI doesn't impact employment", "Reskilling programs, gradual automation, social safety nets, human-AI collaboration", "Ignore employment effects", "Employment impact is positive"], explanation: "Addressing employment impacts requires comprehensive reskilling, thoughtful automation timelines, social support systems, and human-AI collaboration models." },
                        { q: "What is participatory AI design?", a: "Including affected communities in AI system design and development", options: ["AI participation programs", "Including affected communities in AI system design and development", "Participating in AI design", "Community AI participation"], explanation: "Participatory design involves affected communities and stakeholders in the AI development process to ensure systems meet real needs and values." },
                        { q: "How do you handle AI decision contestability?", a: "Appeal processes, human review, explanation mechanisms, correction procedures", options: ["Decisions cannot be contested", "Appeal processes, human review, explanation mechanisms, correction procedures", "Contestability is automatic", "Only legal challenges allowed"], explanation: "AI contestability requires formal appeal processes, human review mechanisms, clear explanations, and procedures for correcting erroneous decisions." },
                        { q: "What is technological determinism vs social shaping?", a: "Determinism sees technology as driving change, social shaping emphasizes human choice", options: ["Technology determines everything", "Determinism sees technology as driving change, social shaping emphasizes human choice", "Social factors don't matter", "Technology and society are unrelated"], explanation: "This debate contrasts views of technology as an autonomous force versus technology as shaped by social choices and capable of being directed toward human values." },
                        { q: "How do you implement AI ethics in global contexts?", a: "Cultural sensitivity, local stakeholder engagement, adaptive frameworks, cross-cultural collaboration", options: ["Use same ethics everywhere", "Cultural sensitivity, local stakeholder engagement, adaptive frameworks, cross-cultural collaboration", "Global ethics don't vary", "Ethics are universal"], explanation: "Global AI ethics requires understanding cultural differences, engaging local stakeholders, developing adaptive frameworks, and fostering cross-cultural ethical dialogue." },
                        { q: "What is the long-term future of AI ethics?", a: "Evolving governance, technological advancement, global cooperation, value alignment challenges", options: ["Ethics will remain static", "Evolving governance, technological advancement, global cooperation, value alignment challenges", "Future ethics are predetermined", "Long-term planning is impossible"], explanation: "AI ethics must evolve with technological advancement, requiring adaptive governance, international cooperation, and ongoing attention to value alignment as AI capabilities grow." }
                    ]
                }
            }
            const getRandomTopic = () => {
                const topicKeys = ['cloud', 'mlops', 'modeling', 'general', 'python_sql', 'production', 'data_eng', 'ethics'];
                return topicKeys[Math.floor(Math.random() * topicKeys.length)];
            };

            const generateQuestion = () => {
                let selectedTopic = currentTopic === 'random' ? getRandomTopic() : currentTopic;
                const topicQuestions = questionBank[selectedTopic][difficulty] || questionBank[selectedTopic][1];
                
                let availableQuestions = topicQuestions.filter(q => !usedQuestions.has(q.q));
                if (availableQuestions.length === 0) {
                    setUsedQuestions(new Set());
                    availableQuestions = topicQuestions;
                }
                
                const randomIndex = Math.floor(Math.random() * availableQuestions.length);
                const selectedQuestion = availableQuestions[randomIndex];
                
                setCurrentQuestion({...selectedQuestion, topic: selectedTopic});
                setUsedQuestions(prev => new Set([...prev, selectedQuestion.q]));
                setUserAnswer('');
                setShowAnswer(false);
            };

            const handleAnswer = (selectedAnswer) => {
                setUserAnswer(selectedAnswer);
                setShowAnswer(true);
                
                const isCorrect = selectedAnswer === currentQuestion.a;
                const questionTopic = currentQuestion.topic;
                const newStreaks = { ...streaks };
                
                if (isCorrect) {
                    newStreaks[questionTopic] += 1;
                    
                    if (difficulty === 1 && newStreaks[questionTopic] >= 3) {
                        setDifficulty(2);
                        newStreaks[questionTopic] = 0;
                    } else if (difficulty === 2 && newStreaks[questionTopic] >= 5) {
                        setDifficulty(3);
                        newStreaks[questionTopic] = 0;
                    }
                } else {
                    newStreaks[questionTopic] = 0;
                    
                    if (difficulty === 3) {
                        setDifficulty(2);
                    } else if (difficulty === 2) {
                        setDifficulty(1);
                    }
                }
                setStreaks(newStreaks);

                setWeeklyStats(prev => ({
                    questionsAnswered: prev.questionsAnswered + 1,
                    correctAnswers: prev.correctAnswers + (isCorrect ? 1 : 0),
                    topicProgress: {
                        ...prev.topicProgress,
                        [questionTopic]: {
                            correct: prev.topicProgress[questionTopic].correct + (isCorrect ? 1 : 0),
                            total: prev.topicProgress[questionTopic].total + 1
                        }
                    }
                }));
            };

            const generateWeeklyReport = () => {
                const accuracy = weeklyStats.questionsAnswered > 0 
                    ? (weeklyStats.correctAnswers / weeklyStats.questionsAnswered * 100).toFixed(1) : 0;

                let strongestTopic = 'cloud';
                let weakestTopic = 'cloud';
                let highestAccuracy = 0;
                let lowestAccuracy = 100;

                Object.keys(weeklyStats.topicProgress).forEach(topic => {
                    const progress = weeklyStats.topicProgress[topic];
                    if (progress.total > 0) {
                        const topicAccuracy = (progress.correct / progress.total) * 100;
                        if (topicAccuracy > highestAccuracy) {
                            highestAccuracy = topicAccuracy;
                            strongestTopic = topic;
                        }
                        if (topicAccuracy < lowestAccuracy && progress.total > 0) {
                            lowestAccuracy = topicAccuracy;
                            weakestTopic = topic;
                        }
                    }
                });

                return {
                    accuracy,
                    strongestTopic: topics[strongestTopic],
                    weakestTopic: topics[weakestTopic],
                    questionsAnswered: weeklyStats.questionsAnswered,
                    recommendations: [
                        `Strongest area: ${topics[strongestTopic]} (${highestAccuracy.toFixed(1)}% accuracy)`,
                        `Focus more on ${topics[weakestTopic]} - current accuracy: ${lowestAccuracy.toFixed(1)}%`,
                        `Current difficulty level: ${difficulty === 1 ? 'Easy' : difficulty === 2 ? 'Medium' : 'Hard'}`,
                        difficulty < 3 ? 
                            `${difficulty === 1 ? 'Get 3 correct in a row' : 'Get 5 correct in a row'} to advance to ${difficulty === 1 ? 'Medium' : 'Hard'}` :
                            'Mastering the hardest questions! Stay focused to maintain this level',
                        `Current streak in ${currentTopic === 'random' ? 'mixed topics' : topics[currentTopic]}: ${currentTopic === 'random' ? Math.max(...Object.values(streaks)) : streaks[currentTopic]} correct answers`
                    ]
                };
            };

            useEffect(() => {
                generateQuestion();
            }, [currentTopic, difficulty]);

            const report = generateWeeklyReport();

            return (
                <div className="min-h-screen bg-gradient-to-br from-indigo-50 via-white to-cyan-50 p-4">
                    <div className="max-w-4xl mx-auto">
                        <div className="text-center mb-8">
                            <div className="flex items-center justify-center mb-4">
                                <Brain className="w-12 h-12 text-indigo-600 mr-3" />
                                <h1 className="text-4xl font-bold bg-gradient-to-r from-indigo-600 to-cyan-600 bg-clip-text text-transparent">
                                    AI/ML Study Quiz
                                </h1>
                            </div>
                            <p className="text-gray-600 text-lg">Adaptive learning powered by Claude AI</p>
                        </div>

                        <div className="bg-white rounded-xl shadow-lg p-6 mb-6">
                            <h2 className="text-xl font-semibold mb-4 flex items-center">
                                <BookOpen className="w-6 h-6 mr-2 text-indigo-600" />
                                Study Mode
                            </h2>
                            <div className="grid grid-cols-2 md:grid-cols-3 gap-3">
                                {Object.entries(topics).filter(([key]) => key !== 'random').map(([key, name]) => (
                                    <button key={key} onClick={() => setCurrentTopic(key)}
                                        className={`p-3 rounded-lg border-2 transition-all ${
                                            currentTopic === key ? 'border-indigo-500 bg-indigo-50 text-indigo-700' : 'border-gray-200 hover:border-indigo-300'
                                        }`}>
                                        <div className="text-sm font-medium">{name}</div>
                                        <div className="flex items-center justify-center mt-2 text-xs">
                                            <TrendingUp className="w-3 h-3 mr-1" />
                                            Streak: {streaks[key]}
                                        </div>
                                    </button>
                                ))}
                                <button key="random" onClick={() => setCurrentTopic('random')}
                                    className={`p-3 rounded-lg border-2 transition-all ${
                                        currentTopic === 'random' ? 'border-indigo-500 bg-indigo-50 text-indigo-700' : 'border-gray-200 hover:border-indigo-300'
                                    }`}>
                                    <div className="text-sm font-medium flex items-center justify-center">
                                        <Shuffle className="w-4 h-4 mr-1" />
                                        Random Mix
                                    </div>
                                </button>
                            </div>
                        </div>

                        <div className="bg-white rounded-xl shadow-lg p-4 mb-6">
                            <div className="flex items-center justify-between">
                                <div className="flex items-center">
                                    <Award className="w-5 h-5 mr-2 text-yellow-500" />
                                    <span className="font-medium">
                                        Difficulty: {difficulty === 1 ? 'Easy' : difficulty === 2 ? 'Medium' : 'Hard'}
                                    </span>
                                </div>
                                <div className="flex space-x-1">
                                    {[1,2,3].map(level => (
                                        <div key={level} className={`w-3 h-3 rounded-full ${level <= difficulty ? 'bg-yellow-400' : 'bg-gray-200'}`} />
                                    ))}
                                </div>
                            </div>
                            <div className="mt-2 text-xs text-gray-600">
                                {difficulty === 1 && "Get 3 correct in a row to advance to Medium"}
                                {difficulty === 2 && "Get 5 correct in a row to advance to Hard"}
                                {difficulty === 3 && "You're at the highest level! One wrong answer demotes you"}
                            </div>
                        </div>

                        {currentQuestion && (
                            <div className="bg-white rounded-xl shadow-lg p-6 mb-6">
                                <div className="flex items-start justify-between mb-4">
                                    <h3 className="text-lg font-semibold">{currentQuestion.q}</h3>
                                    <div className="flex items-center text-sm text-gray-500">
                                        <Lightbulb className="w-4 h-4 mr-1" />
                                        {difficulty === 1 ? 'Easy' : difficulty === 2 ? 'Medium' : 'Hard'}  {topics[currentQuestion.topic]}
                                    </div>
                                </div>

                                <div className="space-y-3 mb-6">
                                    {currentQuestion.options.map((option, index) => (
                                        <button key={index} onClick={() => handleAnswer(option)} disabled={showAnswer}
                                            className={`w-full p-4 text-left rounded-lg border-2 transition-all ${
                                                showAnswer
                                                    ? option === currentQuestion.a ? 'border-green-500 bg-green-50 text-green-700'
                                                    : option === userAnswer && option !== currentQuestion.a ? 'border-red-500 bg-red-50 text-red-700'
                                                    : 'border-gray-200 bg-gray-50'
                                                    : 'border-gray-200 hover:border-indigo-300 hover:bg-indigo-50'
                                            }`}>
                                            <div className="flex items-center">
                                                {showAnswer && option === currentQuestion.a && <CheckCircle className="w-5 h-5 mr-2 text-green-600" />}
                                                {showAnswer && option === userAnswer && option !== currentQuestion.a && <XCircle className="w-5 h-5 mr-2 text-red-600" />}
                                                {option}
                                            </div>
                                        </button>
                                    ))}
                                </div>

                                {showAnswer && (
                                    <div className="border-t pt-4">
                                        <div className={`p-4 rounded-lg ${userAnswer === currentQuestion.a ? 'bg-green-50' : 'bg-blue-50'}`}>
                                            <div className="flex items-center mb-2">
                                                {userAnswer === currentQuestion.a ? (
                                                    <CheckCircle className="w-5 h-5 text-green-600 mr-2" />
                                                ) : (
                                                    <Lightbulb className="w-5 h-5 text-blue-600 mr-2" />
                                                )}
                                                <span className="font-medium">
                                                    {userAnswer === currentQuestion.a ? 'Correct!' : 'Learning Opportunity'}
                                                </span>
                                            </div>
                                            <p className="text-sm text-gray-700 mb-2">
                                                <strong>Correct answer:</strong> {currentQuestion.a}
                                            </p>
                                            <p className="text-sm text-gray-600">
                                                <strong>Explanation:</strong> {currentQuestion.explanation}
                                            </p>
                                        </div>
                                        <button onClick={generateQuestion}
                                            className="mt-4 w-full bg-indigo-600 text-white py-3 rounded-lg hover:bg-indigo-700 transition-colors flex items-center justify-center">
                                            <RotateCcw className="w-5 h-5 mr-2" />
                                            Next Question
                                        </button>
                                    </div>
                                )}
                            </div>
                        )}

                        <div className="text-center mb-6">
                            <button onClick={() => setShowWeeklyReport(!showWeeklyReport)}
                                className="bg-cyan-600 text-white px-6 py-3 rounded-lg hover:bg-cyan-700 transition-colors flex items-center mx-auto">
                                <BarChart3 className="w-5 h-5 mr-2" />
                                {showWeeklyReport ? 'Hide' : 'Show'} Progress Report
                            </button>
                        </div>

                        {showWeeklyReport && (
                            <div className="bg-white rounded-xl shadow-lg p-6">
                                <h3 className="text-xl font-semibold mb-4 flex items-center">
                                    <BarChart3 className="w-6 h-6 mr-2 text-cyan-600" />
                                    Progress Report
                                </h3>
                                
                                <div className="grid grid-cols-1 md:grid-cols-3 gap-4 mb-6">
                                    <div className="bg-gradient-to-br from-blue-50 to-indigo-50 p-4 rounded-lg">
                                        <div className="text-2xl font-bold text-indigo-700">{report.accuracy}%</div>
                                        <div className="text-sm text-gray-600">Overall Accuracy</div>
                                    </div>
                                    <div className="bg-gradient-to-br from-green-50 to-emerald-50 p-4 rounded-lg">
                                        <div className="text-2xl font-bold text-green-700">{report.questionsAnswered}</div>
                                        <div className="text-sm text-gray-600">Questions Answered</div>
                                    </div>
                                    <div className="bg-gradient-to-br from-purple-50 to-pink-50 p-4 rounded-lg">
                                        <div className="text-lg font-bold text-purple-700">{report.strongestTopic}</div>
                                        <div className="text-sm text-gray-600">Strongest Topic</div>
                                    </div>
                                </div>

                                <div className="mb-4">
                                    <h4 className="font-medium mb-2">Topic Performance Breakdown:</h4>
                                    <div className="space-y-2">
                                        {Object.entries(topics).filter(([key]) => key !== 'random').map(([key, name]) => {
                                            const progress = weeklyStats.topicProgress[key];
                                            const accuracy = progress.total > 0 ? (progress.correct / progress.total * 100).toFixed(1) : 0;
                                            const isStrongest = name === report.strongestTopic;
                                            const isWeakest = name === report.weakestTopic && progress.total > 0;
                                            return (
                                                <div key={key} className={`flex items-center justify-between text-sm p-2 rounded ${
                                                    isStrongest ? 'bg-green-50 border border-green-200' : 
                                                    isWeakest ? 'bg-red-50 border border-red-200' : 
                                                    'bg-gray-50'
                                                }`}>
                                                    <span className="flex items-center">
                                                        {isStrongest && <span className="text-green-600 mr-1"></span>}
                                                        {isWeakest && <span className="text-red-600 mr-1"></span>}
                                                        {name}
                                                    </span>
                                                    <span className={
                                                        isStrongest ? 'text-green-700 font-medium' :
                                                        isWeakest ? 'text-red-700 font-medium' :
                                                        'text-gray-700'
                                                    }>
                                                        {accuracy}% ({progress.correct}/{progress.total}) | Streak: {streaks[key]}
                                                    </span>
                                                </div>
                                            );
                                        })}
                                    </div>
                                </div>

                                <div>
                                    <h4 className="font-medium mb-2">Smart Recommendations:</h4>
                                    <ul className="text-sm text-gray-700 space-y-1">
                                        {report.recommendations.map((rec, index) => (
                                            <li key={index} className="flex items-start">
                                                <span className="w-2 h-2 bg-cyan-500 rounded-full mt-2 mr-2 flex-shrink-0"></span>
                                                {rec}
                                            </li>
                                        ))}
                                    </ul>
                                </div>
                            </div>
                        )}

                        <div className="text-center mt-8 text-gray-500 text-sm">
                            <p>Powered by Claude AI  Auto-saves progress  Questions adapt to your performance</p>
                        </div>
                    </div>
                </div>
            );
        };

        ReactDOM.render(React.createElement(AIMLQuizApp), document.getElementById('root'));
    </script>
</body>
</html>