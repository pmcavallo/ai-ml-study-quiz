<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI/ML Study Quiz</title>
    <script src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useEffect } = React;

        // Icon components
        const BookOpen = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <path d="M2 3h6a4 4 0 0 1 4 4v14a3 3 0 0 0-3-3H2z"/>
                <path d="M22 3h-6a4 4 0 0 0-4 4v14a3 3 0 0 1 3-3h7z"/>
            </svg>
        );

        const Brain = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <path d="M9.5 2A2.5 2.5 0 0 1 12 4.5v15a2.5 2.5 0 0 1-4.96.44 2.5 2.5 0 0 1-2.96-3.08 3 3 0 0 1-.34-5.58 2.5 2.5 0 0 1 1.32-4.24 2.5 2.5 0 0 1 1.98-3A2.5 2.5 0 0 1 9.5 2Z"/>
                <path d="M14.5 2A2.5 2.5 0 0 0 12 4.5v15a2.5 2.5 0 0 0 4.96.44 2.5 2.5 0 0 0 2.96-3.08 3 3 0 0 0 .34-5.58 2.5 2.5 0 0 0-1.32-4.24 2.5 2.5 0 0 0-1.98-3A2.5 2.5 0 0 0 14.5 2Z"/>
            </svg>
        );

        const Award = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <circle cx="12" cy="8" r="6"/>
                <path d="M15.477 12.89 17 22l-5-3-5 3 1.523-9.11"/>
            </svg>
        );

        const TrendingUp = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <polyline points="22,7 13.5,15.5 8.5,10.5 2,17"/>
                <polyline points="16,7 22,7 22,13"/>
            </svg>
        );

        const RotateCcw = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <path d="M3 12a9 9 0 1 0 9-9 9.75 9.75 0 0 0-6.74 2.74L3 8"/>
                <path d="M3 3v5h5"/>
            </svg>
        );

        const CheckCircle = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                <polyline points="22,4 12,14.01 9,11.01"/>
            </svg>
        );

        const XCircle = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <circle cx="12" cy="12" r="10"/>
                <path d="M15 9l-6 6"/>
                <path d="M9 9l6 6"/>
            </svg>
        );

        const Lightbulb = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <path d="M15 14c.2-1 .7-1.7 1.5-2.5 1-.9 1.5-2.2 1.5-3.5A6 6 0 0 0 6 8c0 1 .2 2.2 1.5 3.5.7.7 1.3 1.5 1.5 2.5"/>
                <path d="M9 18h6"/>
                <path d="M10 22h4"/>
            </svg>
        );

        const BarChart3 = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <path d="M3 3v18h18"/>
                <path d="M18 17V9"/>
                <path d="M13 17V5"/>
                <path d="M8 17v-3"/>
            </svg>
        );

        const Shuffle = ({ className }) => (
            <svg className={className} xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round">
                <polyline points="16,3 21,3 21,8"/>
                <line x1="4" y1="20" x2="21" y2="3"/>
                <polyline points="21,16 21,21 16,21"/>
                <line x1="15" y1="15" x2="21" y2="21"/>
                <line x1="4" y1="4" x2="9" y2="9"/>
            </svg>
        );

        const AIMLQuizApp = () => {
            const [currentTopic, setCurrentTopic] = useState('random');
            const [difficulty, setDifficulty] = useState(1);
            const [currentQuestion, setCurrentQuestion] = useState(null);
            const [userAnswer, setUserAnswer] = useState('');
            const [showAnswer, setShowAnswer] = useState(false);
            const [usedQuestions, setUsedQuestions] = useState(new Set());
            const [streaks, setStreaks] = useState({
                cloud: 0, mlops: 0, modeling: 0, general: 0, python_sql: 0, production: 0, data_eng: 0, ethics: 0
            });
            const [weeklyStats, setWeeklyStats] = useState({
                questionsAnswered: 0,
                correctAnswers: 0,
                topicProgress: {
                    cloud: { correct: 0, total: 0 },
                    mlops: { correct: 0, total: 0 },
                    modeling: { correct: 0, total: 0 },
                    general: { correct: 0, total: 0 },
                    python_sql: { correct: 0, total: 0 },
                    production: { correct: 0, total: 0 },
                    data_eng: { correct: 0, total: 0 },
                    ethics: { correct: 0, total: 0 }
                }
            });
            const [showWeeklyReport, setShowWeeklyReport] = useState(false);

            const topics = {
                cloud: 'Cloud (AWS/GCP)',
                mlops: 'MLOps',
                modeling: 'Modeling & Deployment',
                general: 'AI General Knowledge',
                python_sql: 'Python/SQL Coding',
                production: 'AI in Production',
                data_eng: 'Data Engineering for ML',
                ethics: 'AI Ethics & Fairness',
                random: 'Random Mix'
            };

            const questionBank = {
                cloud: {
                    1: [
                        { q: "What does S3 stand for in AWS?", a: "Simple Storage Service", options: ["Simple Storage Service", "Scalable Storage System", "Secure Storage Solution", "Smart Storage Service"], explanation: "S3 stands for Simple Storage Service, AWS's object storage service designed for scalability, data availability, security, and performance." },
                        { q: "Which GCP service is equivalent to AWS Lambda?", a: "Cloud Functions", options: ["Cloud Functions", "Cloud Run", "App Engine", "Compute Engine"], explanation: "Cloud Functions is Google's serverless compute service, directly equivalent to AWS Lambda for running code without managing servers." },
                        { q: "What is the main purpose of AWS IAM?", a: "Identity and Access Management", options: ["Internet Access Management", "Identity and Access Management", "Infrastructure Asset Management", "Internal Application Monitoring"], explanation: "IAM (Identity and Access Management) controls who can access AWS resources and what they can do with them." },
                        { q: "What does EC2 stand for in AWS?", a: "Elastic Compute Cloud", options: ["Elastic Compute Cloud", "Enhanced Cloud Computing", "Enterprise Computing Center", "Elastic Container Cloud"], explanation: "EC2 (Elastic Compute Cloud) provides resizable compute capacity in the cloud, allowing you to run virtual servers." },
                        { q: "Which AWS service provides managed relational databases?", a: "RDS", options: ["DynamoDB", "RDS", "DocumentDB", "Neptune"], explanation: "RDS (Relational Database Service) makes it easy to set up, operate, and scale relational databases in the cloud." },
                        { q: "What is the default storage class for S3 objects?", a: "Standard", options: ["Standard", "Intelligent-Tiering", "Standard-IA", "Glacier"], explanation: "S3 Standard is the default storage class, providing high durability, availability, and performance for frequently accessed data." },
                        { q: "Which GCP service is used for big data analytics?", a: "BigQuery", options: ["BigQuery", "Cloud SQL", "Firestore", "Cloud Spanner"], explanation: "BigQuery is Google's fully-managed, serverless data warehouse designed for large-scale data analytics." },
                        { q: "What is the AWS equivalent of Google Cloud Storage?", a: "S3", options: ["EBS", "EFS", "S3", "Glacier"], explanation: "S3 (Simple Storage Service) is AWS's object storage service, equivalent to Google Cloud Storage." },
                        { q: "Which AWS service provides content delivery network (CDN)?", a: "CloudFront", options: ["CloudFront", "Route 53", "API Gateway", "CloudWatch"], explanation: "CloudFront is AWS's content delivery network service that delivers data, videos, applications, and APIs globally with low latency." },
                        { q: "What does VPC stand for in cloud computing?", a: "Virtual Private Cloud", options: ["Virtual Private Cloud", "Virtual Public Cloud", "Very Private Computing", "Virtual Processing Center"], explanation: "VPC (Virtual Private Cloud) lets you provision a logically isolated section of the cloud where you can launch resources in a virtual network." },
                        { q: "Which GCP service provides managed Kubernetes?", a: "GKE", options: ["GCE", "GKE", "Cloud Run", "App Engine"], explanation: "GKE (Google Kubernetes Engine) is a managed Kubernetes service that simplifies deploying, managing, and scaling containerized applications." },
                        { q: "What is the purpose of AWS CloudWatch?", a: "Monitoring and logging", options: ["Load balancing", "Monitoring and logging", "Database management", "File storage"], explanation: "CloudWatch is AWS's monitoring and observability service that provides data and actionable insights for applications and infrastructure." },
                        { q: "Which AWS service provides serverless computing?", a: "Lambda", options: ["EC2", "Lambda", "ECS", "Batch"], explanation: "AWS Lambda lets you run code without provisioning or managing servers, charging only for compute time consumed." },
                        { q: "What is the GCP equivalent of AWS EC2?", a: "Compute Engine", options: ["Cloud Functions", "App Engine", "Compute Engine", "Cloud Run"], explanation: "Compute Engine provides virtual machines that run on Google's infrastructure, similar to AWS EC2." },
                        { q: "Which AWS service provides managed NoSQL database?", a: "DynamoDB", options: ["RDS", "DynamoDB", "ElastiCache", "Redshift"], explanation: "DynamoDB is AWS's fully managed NoSQL database service that provides fast and predictable performance with seamless scalability." },
                        { q: "What does auto-scaling do in cloud computing?", a: "Automatically adjusts resource capacity", options: ["Automatically adjusts resource capacity", "Automatically backs up data", "Automatically updates software", "Automatically encrypts data"], explanation: "Auto-scaling automatically adjusts the number of compute resources allocated to your application based on demand." }
                    ],
                    2: [
                        { q: "What is the difference between AWS ECS and EKS?", a: "ECS is AWS container service, EKS is managed Kubernetes", options: ["ECS is AWS container service, EKS is managed Kubernetes", "ECS is for databases, EKS is for storage", "No practical difference", "ECS is newer than EKS"], explanation: "ECS (Elastic Container Service) is AWS's proprietary container orchestration, while EKS (Elastic Kubernetes Service) is AWS's managed Kubernetes offering." },
                        { q: "What is AWS CloudFormation used for?", a: "Infrastructure as Code", options: ["Data analytics", "Infrastructure as Code", "Machine learning", "Content delivery"], explanation: "CloudFormation allows you to define cloud infrastructure using templates, enabling version control and repeatable deployments." },
                        { q: "Which GCP service provides serverless SQL databases?", a: "Cloud SQL", options: ["BigQuery", "Cloud SQL", "Firestore", "Cloud Spanner"], explanation: "Cloud SQL is a fully-managed relational database service for MySQL, PostgreSQL, and SQL Server." },
                        { q: "What is the difference between horizontal and vertical scaling?", a: "Horizontal adds more instances, vertical adds more power", options: ["Horizontal adds more instances, vertical adds more power", "Horizontal is always better", "Vertical is always cheaper", "No practical difference"], explanation: "Horizontal scaling adds more instances of resources, while vertical scaling increases the power (CPU, RAM) of existing instances." },
                        { q: "What is AWS Route 53 used for?", a: "Domain Name System (DNS) web service", options: ["Load balancing only", "Domain Name System (DNS) web service", "Content delivery", "Database routing"], explanation: "Route 53 is AWS's scalable DNS web service designed to route end users to Internet applications reliably." },
                        { q: "What is the purpose of AWS Elastic Load Balancer?", a: "Distribute incoming traffic across multiple targets", options: ["Store static files", "Distribute incoming traffic across multiple targets", "Monitor application performance", "Manage user authentication"], explanation: "Elastic Load Balancing automatically distributes incoming application traffic across multiple targets, such as EC2 instances." },
                        { q: "Which GCP service is equivalent to AWS CloudFormation?", a: "Deployment Manager", options: ["Cloud Build", "Deployment Manager", "Cloud Composer", "Resource Manager"], explanation: "Google Cloud Deployment Manager allows you to specify all resources needed for your application in a declarative format using YAML." },
                        { q: "What is the difference between S3 Standard and S3 Standard-IA?", a: "Standard-IA is for infrequently accessed data with lower cost", options: ["Standard-IA is faster", "Standard-IA is for infrequently accessed data with lower cost", "Standard-IA has better durability", "No difference"], explanation: "S3 Standard-IA (Infrequent Access) offers lower storage costs for data accessed less frequently but requires rapid access when needed." },
                        { q: "What is AWS API Gateway used for?", a: "Creating and managing APIs", options: ["Database management", "Creating and managing APIs", "File storage", "User authentication"], explanation: "API Gateway is a fully managed service for creating, publishing, maintaining, monitoring, and securing REST, HTTP, and WebSocket APIs." },
                        { q: "Which AWS service provides managed message queuing?", a: "SQS", options: ["SNS", "SQS", "SES", "Kinesis"], explanation: "SQS (Simple Queue Service) is a fully managed message queuing service that enables decoupling and scaling of microservices." },
                        { q: "What is the purpose of AWS CloudTrail?", a: "API logging and monitoring", options: ["Performance monitoring", "API logging and monitoring", "Cost optimization", "Security scanning"], explanation: "CloudTrail provides governance, compliance, operational auditing, and risk auditing of your AWS account by logging API calls." },
                        { q: "Which GCP service provides managed Apache Spark and Hadoop?", a: "Dataproc", options: ["BigQuery", "Dataflow", "Dataproc", "Cloud Composer"], explanation: "Dataproc is a fast, easy-to-use, fully managed cloud service for running Apache Spark and Apache Hadoop clusters." },
                        { q: "What is AWS Elastic Beanstalk?", a: "Platform-as-a-Service for deploying applications", options: ["Infrastructure monitoring", "Platform-as-a-Service for deploying applications", "Database service", "Content delivery network"], explanation: "Elastic Beanstalk is an easy-to-use service for deploying and scaling web applications and services with popular development platforms." },
                        { q: "What is the difference between AWS SNS and SQS?", a: "SNS is pub/sub messaging, SQS is message queuing", options: ["SNS is faster", "SNS is pub/sub messaging, SQS is message queuing", "SQS is more reliable", "No difference"], explanation: "SNS (Simple Notification Service) is a pub/sub messaging service, while SQS provides message queuing for decoupling applications." },
                        { q: "Which AWS service provides managed Apache Kafka?", a: "MSK (Managed Streaming for Kafka)", options: ["Kinesis", "SQS", "MSK (Managed Streaming for Kafka)", "SNS"], explanation: "Amazon MSK is a fully managed service that makes it easy to build and run applications that use Apache Kafka." },
                        { q: "What is AWS CodePipeline used for?", a: "Continuous integration and continuous delivery", options: ["Code storage", "Continuous integration and continuous delivery", "Code editing", "Code documentation"], explanation: "CodePipeline is a continuous integration and continuous delivery service for fast and reliable application and infrastructure updates." }
                    ],
                    3: [
                        { q: "What does the CAP theorem state about distributed systems?", a: "You can only guarantee 2 of 3: Consistency, Availability, Partition tolerance", options: ["You can only guarantee 2 of 3: Consistency, Availability, Partition tolerance", "All three can be guaranteed simultaneously", "Only applies to SQL databases", "Related to network security"], explanation: "The CAP theorem proves that distributed systems can only guarantee two of three properties: Consistency, Availability, and Partition tolerance." },
                        { q: "How would you design a multi-region disaster recovery strategy in AWS?", a: "Use cross-region replication, backup strategies, and failover mechanisms", options: ["Just backup data regularly", "Use cross-region replication, backup strategies, and failover mechanisms", "Keep everything in one region", "Only use local backups"], explanation: "Multi-region DR requires cross-region data replication, automated failover, backup strategies, and regular testing of recovery procedures." },
                        { q: "What is the difference between AWS Transit Gateway and VPC Peering?", a: "Transit Gateway provides centralized connectivity, VPC Peering is point-to-point", options: ["Transit Gateway is slower", "Transit Gateway provides centralized connectivity, VPC Peering is point-to-point", "No practical difference", "VPC Peering is more secure"], explanation: "Transit Gateway acts as a hub for connecting VPCs and on-premises networks, while VPC Peering creates direct connections between two VPCs." },
                        { q: "How would you implement blue-green deployment in the cloud?", a: "Maintain two identical environments and switch traffic between them", options: ["Use different colored servers", "Maintain two identical environments and switch traffic between them", "Deploy only during off-hours", "Use A/B testing"], explanation: "Blue-green deployment maintains two identical production environments, allowing instant switching with zero downtime and easy rollback." },
                        { q: "What are the security best practices for cloud IAM?", a: "Principle of least privilege, MFA, regular rotation, monitoring", options: ["Give everyone admin access", "Principle of least privilege, MFA, regular rotation, monitoring", "Use only root accounts", "Disable all logging"], explanation: "IAM security requires least privilege access, multi-factor authentication, regular credential rotation, and comprehensive monitoring." },
                        { q: "How do you optimize costs in a cloud environment?", a: "Right-sizing, reserved instances, auto-scaling, monitoring unused resources", options: ["Always use the largest instances", "Right-sizing, reserved instances, auto-scaling, monitoring unused resources", "Keep all resources running", "Only use on-demand pricing"], explanation: "Cost optimization involves right-sizing resources, using reserved instances, implementing auto-scaling, and regularly monitoring for unused resources." },
                        { q: "What is the difference between stateful and stateless applications in cloud architecture?", a: "Stateless apps don't store session data, stateful apps do", options: ["Stateless apps are slower", "Stateless apps don't store session data, stateful apps do", "Stateful apps are more secure", "No practical difference"], explanation: "Stateless applications don't store session information between requests, making them easier to scale and more fault-tolerant than stateful applications." },
                        { q: "How would you implement a microservices architecture in the cloud?", a: "Use containers, service mesh, API gateways, and independent databases", options: ["Use a single large server", "Use containers, service mesh, API gateways, and independent databases", "Keep everything in one database", "Avoid using containers"], explanation: "Microservices architecture requires containerization, service mesh for communication, API gateways for routing, and database per service pattern." },
                        { q: "What is eventual consistency in distributed systems?", a: "System will become consistent over time without immediate consistency", options: ["Data is always immediately consistent", "System will become consistent over time without immediate consistency", "Data is never consistent", "Only applies to NoSQL databases"], explanation: "Eventual consistency guarantees that if no new updates are made, all replicas will eventually converge to the same value." },
                        { q: "How do you implement observability in cloud applications?", a: "Combine metrics, logs, and traces with monitoring tools", options: ["Only use basic logging", "Combine metrics, logs, and traces with monitoring tools", "Just monitor CPU usage", "Observability is not necessary"], explanation: "Observability requires the three pillars: metrics (numerical data), logs (event records), and traces (request flows) with appropriate monitoring tools." },
                        { q: "What are the challenges of container orchestration at scale?", a: "Service discovery, load balancing, health monitoring, security, networking", options: ["Containers are always easy to manage", "Service discovery, load balancing, health monitoring, security, networking", "No challenges exist", "Only storage is challenging"], explanation: "Container orchestration at scale requires managing service discovery, load balancing, health monitoring, security policies, and complex networking." },
                        { q: "How would you design a highly available database architecture?", a: "Use read replicas, multi-AZ deployment, automated backups, and failover", options: ["Use a single database instance", "Use read replicas, multi-AZ deployment, automated backups, and failover", "Databases don't need high availability", "Manual backups are sufficient"], explanation: "High availability databases require read replicas for scaling, multi-AZ deployment for redundancy, automated backups, and automatic failover mechanisms." },
                        { q: "What is the shared responsibility model in cloud security?", a: "Cloud provider secures infrastructure, customer secures data and applications", options: ["Cloud provider handles all security", "Cloud provider secures infrastructure, customer secures data and applications", "Customer handles all security", "Security is not important in cloud"], explanation: "The shared responsibility model divides security duties: cloud providers secure the infrastructure, customers secure their data, applications, and configurations." },
                        { q: "How do you implement zero-downtime deployments?", a: "Use rolling updates, canary deployments, or blue-green strategies", options: ["Accept downtime as normal", "Use rolling updates, canary deployments, or blue-green strategies", "Deploy only at night", "Stop all services during deployment"], explanation: "Zero-downtime deployments use strategies like rolling updates, canary deployments, or blue-green deployments to update applications without service interruption." },
                        { q: "What are the considerations for cloud vendor lock-in?", a: "Use open standards, abstract vendor-specific services, plan exit strategies", options: ["Vendor lock-in is always bad", "Use open standards, abstract vendor-specific services, plan exit strategies", "Lock-in is unavoidable", "Only use proprietary services"], explanation: "Avoiding vendor lock-in requires using open standards, abstracting vendor-specific services, maintaining portable architectures, and planning exit strategies." },
                        { q: "How do you implement compliance and governance in cloud environments?", a: "Use policy as code, compliance frameworks, audit trails, and automated scanning", options: ["Compliance is not necessary", "Use policy as code, compliance frameworks, audit trails, and automated scanning", "Manual processes are sufficient", "Governance slows down development"], explanation: "Cloud governance requires policy as code implementation, compliance framework adoption, comprehensive audit trails, and automated security scanning." }
                    ]
                },
                modeling: {
                    1: [
                        { q: "What is overfitting in machine learning?", a: "Model performs well on training data but poorly on test data", options: ["Model is too simple", "Model performs well on training data but poorly on test data", "Model trains too slowly", "Model uses too much memory"], explanation: "Overfitting occurs when a model learns the training data too specifically, including noise, making it perform poorly on new, unseen data." },
                        { q: "What is the purpose of regularization?", a: "Prevent overfitting by adding penalty to model complexity", options: ["Speed up training", "Prevent overfitting by adding penalty to model complexity", "Improve data quality", "Reduce memory usage"], explanation: "Regularization adds penalties for model complexity to the loss function, helping prevent overfitting by encouraging simpler models." },
                        { q: "What is cross-validation?", a: "Technique to assess model performance using multiple train/test splits", options: ["Method to clean data", "Technique to assess model performance using multiple train/test splits", "Way to select features", "Process to optimize hyperparameters"], explanation: "Cross-validation evaluates model performance by splitting data into multiple folds and testing on each fold while training on the others." },
                        { q: "What is a confusion matrix?", a: "Table showing actual vs predicted classifications", options: ["Matrix of confusing data points", "Table showing actual vs predicted classifications", "Feature correlation matrix", "Model weight matrix"], explanation: "A confusion matrix displays the performance of a classification model by showing actual versus predicted class labels." },
                        { q: "What is feature selection?", a: "Choosing the most relevant features for model training", options: ["Selecting model parameters", "Choosing the most relevant features for model training", "Picking training algorithms", "Selecting data samples"], explanation: "Feature selection identifies and selects the most relevant features that contribute to model performance while removing irrelevant ones." },
                        { q: "What is the difference between classification and regression?", a: "Classification predicts categories, regression predicts continuous values", options: ["Classification is faster", "Classification predicts categories, regression predicts continuous values", "Regression is more accurate", "No practical difference"], explanation: "Classification predicts discrete categories or classes, while regression predicts continuous numerical values." },
                        { q: "What is a decision tree?", a: "Tree-like model that makes decisions based on feature conditions", options: ["Database structure", "Tree-like model that makes decisions based on feature conditions", "Visualization tool", "Data storage format"], explanation: "Decision trees use a tree-like structure to make predictions by following branches based on feature value conditions." },
                        { q: "What is ensemble learning?", a: "Combining multiple models to improve performance", options: ["Training one model multiple times", "Combining multiple models to improve performance", "Using ensemble datasets", "Parallel model training"], explanation: "Ensemble learning combines predictions from multiple models to achieve better performance than individual models." },
                        { q: "What is gradient descent?", a: "Optimization algorithm to minimize loss function", options: ["Feature scaling technique", "Optimization algorithm to minimize loss function", "Model validation method", "Data preprocessing step"], explanation: "Gradient descent is an iterative optimization algorithm that finds the minimum of a loss function by moving in the direction of steepest descent." },
                        { q: "What is the training-validation-test split?", a: "Dividing data into three sets for model development and evaluation", options: ["Three different algorithms", "Dividing data into three sets for model development and evaluation", "Three training phases", "Three model types"], explanation: "Data is split into training (model learning), validation (hyperparameter tuning), and test (final evaluation) sets." },
                        { q: "What is overfitting vs underfitting?", a: "Overfitting is too complex, underfitting is too simple", options: ["Overfitting is too complex, underfitting is too simple", "Overfitting is faster training", "Underfitting uses more data", "They're the same issue"], explanation: "Overfitting occurs when a model is too complex and memorizes training data, while underfitting occurs when a model is too simple to capture patterns." },
                        { q: "What is feature engineering?", a: "Creating new features from existing data", options: ["Model architecture design", "Creating new features from existing data", "Hyperparameter tuning", "Data collection process"], explanation: "Feature engineering involves creating, transforming, or selecting features from raw data to improve model performance." },
                        { q: "What is a learning curve?", a: "Plot showing model performance vs training set size", options: ["Algorithm complexity graph", "Plot showing model performance vs training set size", "Feature importance ranking", "Model architecture diagram"], explanation: "Learning curves plot model performance (accuracy/error) against training set size to diagnose bias and variance issues." },
                        { q: "What is hyperparameter tuning?", a: "Optimizing model configuration parameters", options: ["Adjusting data parameters", "Optimizing model configuration parameters", "Tuning hardware settings", "Adjusting feature weights"], explanation: "Hyperparameter tuning involves finding the best configuration parameters (learning rate, regularization, etc.) for optimal model performance." },
                        { q: "What is the curse of dimensionality?", a: "Performance degradation as feature dimensions increase", options: ["Too many models to choose from", "Performance degradation as feature dimensions increase", "Computational complexity issues", "Memory storage problems"], explanation: "The curse of dimensionality refers to various phenomena that arise when analyzing data in high-dimensional spaces, leading to sparse data and degraded performance." },
                        { q: "What is precision vs recall?", a: "Precision is true positives / predicted positives, recall is true positives / actual positives", options: ["Precision is accuracy, recall is speed", "Precision is true positives / predicted positives, recall is true positives / actual positives", "Precision is for regression, recall for classification", "No practical difference"], explanation: "Precision measures the accuracy of positive predictions, while recall measures the ability to find all actual positive instances." },
                        { q: "What is the F1 score?", a: "Harmonic mean of precision and recall", options: ["First feature importance score", "Harmonic mean of precision and recall", "Final model accuracy", "Feature selection metric"], explanation: "The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both measures." }
                    ],
                    2: [
                        { q: "What is the difference between L1 and L2 regularization?", a: "L1 creates sparse models, L2 shrinks weights evenly", options: ["No practical difference", "L1 creates sparse models, L2 shrinks weights evenly", "L2 is always better", "L1 only works with neural networks"], explanation: "L1 regularization can drive some weights to exactly zero (feature selection), while L2 regularization shrinks all weights proportionally towards zero." },
                        { q: "What is the bias-variance tradeoff?", a: "Balance between model's ability to fit training data vs generalize to new data", options: ["Choice between different algorithms", "Balance between model's ability to fit training data vs generalize to new data", "Speed vs accuracy tradeoff", "Memory vs performance tradeoff"], explanation: "The bias-variance tradeoff describes the balance between a model's ability to capture underlying patterns (bias) and its sensitivity to small changes in training data (variance)." },
                        { q: "What is bagging in ensemble methods?", a: "Bootstrap aggregating - training models on different data samples", options: ["Putting models in bags", "Bootstrap aggregating - training models on different data samples", "Model compression technique", "Feature selection method"], explanation: "Bagging trains multiple models on bootstrap samples of the training data and averages their predictions to reduce variance." },
                        { q: "What is boosting in machine learning?", a: "Sequential training where models learn from previous errors", options: ["Increasing model performance", "Sequential training where models learn from previous errors", "Parallel model training", "Model acceleration technique"], explanation: "Boosting sequentially trains models where each new model focuses on correcting errors made by previous models." },
                        { q: "What is random forest?", a: "Ensemble of decision trees with random feature selection", options: ["Trees planted randomly", "Ensemble of decision trees with random feature selection", "Random data sampling", "Randomized neural network"], explanation: "Random Forest combines multiple decision trees trained on random subsets of data and features, then averages their predictions." },
                        { q: "What is support vector machine (SVM)?", a: "Algorithm that finds optimal boundary between classes", options: ["Vector calculation method", "Algorithm that finds optimal boundary between classes", "Support system for models", "Matrix operation technique"], explanation: "SVM finds the optimal hyperplane that maximally separates different classes by maximizing the margin between them." },
                        { q: "What is k-means clustering?", a: "Unsupervised algorithm that groups data into k clusters", options: ["K different algorithms", "Unsupervised algorithm that groups data into k clusters", "K-fold validation method", "Feature selection technique"], explanation: "K-means partitions data into k clusters by minimizing within-cluster variance and maximizing between-cluster variance." },
                        { q: "What is principal component analysis (PCA)?", a: "Dimensionality reduction technique using principal components", options: ["Primary component analysis", "Dimensionality reduction technique using principal components", "Performance component assessment", "Process control analysis"], explanation: "PCA reduces dimensionality by finding principal components that capture the most variance in the data." },
                        { q: "What is the ROC curve?", a: "Plot of true positive rate vs false positive rate", options: ["Receiver operating characteristic", "Plot of true positive rate vs false positive rate", "Rate of change curve", "Regression output curve"], explanation: "ROC curves plot the true positive rate against false positive rate at various threshold settings, helping evaluate binary classifiers." },
                        { q: "What is AUC in machine learning?", a: "Area under the ROC curve, measures classifier performance", options: ["Advanced unit calculation", "Area under the ROC curve, measures classifier performance", "Automated user classification", "Algorithm usage count"], explanation: "AUC (Area Under the Curve) measures the entire two-dimensional area underneath the ROC curve, providing a single scalar performance metric." },
                        { q: "What is stratified sampling?", a: "Sampling that maintains class proportions from original dataset", options: ["Sampling in layers", "Sampling that maintains class proportions from original dataset", "Random sampling method", "Sequential sampling technique"], explanation: "Stratified sampling ensures that each class is represented proportionally in the sample as they appear in the original dataset." },
                        { q: "What is feature scaling?", a: "Normalizing features to similar ranges", options: ["Scaling model size", "Normalizing features to similar ranges", "Feature importance ranking", "Feature selection process"], explanation: "Feature scaling transforms features to similar scales (like 0-1 or standard normal) to ensure no feature dominates due to its scale." },
                        { q: "What is cross-entropy loss?", a: "Loss function commonly used for classification problems", options: ["Cross-validation error", "Loss function commonly used for classification problems", "Entropy between datasets", "Cross-feature correlation"], explanation: "Cross-entropy loss measures the difference between predicted probability distributions and true class labels in classification." },
                        { q: "What is early stopping?", a: "Stopping training when validation performance stops improving", options: ["Stopping training early to save time", "Stopping training when validation performance stops improving", "Emergency training halt", "Scheduled training termination"], explanation: "Early stopping prevents overfitting by monitoring validation performance and stopping training when it begins to degrade." },
                        { q: "What is batch vs stochastic gradient descent?", a: "Batch uses all data, stochastic uses one sample per update", options: ["Batch is faster", "Batch uses all data, stochastic uses one sample per update", "Stochastic is more accurate", "No practical difference"], explanation: "Batch gradient descent uses the entire dataset for each update, while stochastic gradient descent uses one sample at a time." },
                        { q: "What is dropout in neural networks?", a: "Randomly setting some neurons to zero during training", options: ["Removing bad data points", "Randomly setting some neurons to zero during training", "Stopping training early", "Dropping unnecessary features"], explanation: "Dropout randomly sets a fraction of neurons to zero during training to prevent overfitting and improve generalization." }
                    ],
                    3: [
                        { q: "How would you handle class imbalance in a dataset?", a: "Use techniques like SMOTE, class weights, or different evaluation metrics", options: ["Ignore the imbalance", "Use techniques like SMOTE, class weights, or different evaluation metrics", "Always use more data", "Only use precision as metric"], explanation: "Class imbalance can be addressed through sampling techniques (SMOTE), adjusting class weights, using appropriate metrics (F1, AUC), or ensemble methods." },
                        { q: "What is the difference between bagging and boosting?", a: "Bagging trains models in parallel, boosting trains sequentially with error correction", options: ["No difference in practice", "Bagging trains models in parallel, boosting trains sequentially with error correction", "Bagging is always faster", "Boosting only works with decision trees"], explanation: "Bagging trains models independently in parallel and averages results, while boosting trains models sequentially where each corrects previous errors." },
                        { q: "How do you detect and handle overfitting?", a: "Monitor validation curves, use regularization, cross-validation, early stopping", options: ["Overfitting is always good", "Monitor validation curves, use regularization, cross-validation, early stopping", "Just use more data", "Overfitting cannot be detected"], explanation: "Overfitting detection involves monitoring training vs validation performance gaps and using techniques like regularization, cross-validation, and early stopping." },
                        { q: "What is transfer learning and when would you use it?", a: "Using pre-trained models as starting point, useful with limited data", options: ["Transferring data between models", "Using pre-trained models as starting point, useful with limited data", "Moving models between servers", "Transferring learning algorithms"], explanation: "Transfer learning leverages knowledge from pre-trained models, especially useful when you have limited training data for your specific task." },
                        { q: "How do you choose the right evaluation metric?", a: "Depends on problem type, class balance, business objectives, and costs", options: ["Always use accuracy", "Depends on problem type, class balance, business objectives, and costs", "Use the highest scoring metric", "Metrics don't matter"], explanation: "Metric selection depends on problem characteristics (classification/regression), class distribution, business goals, and relative costs of different error types." },
                        { q: "What is model interpretability and why is it important?", a: "Understanding how models make decisions, crucial for trust and compliance", options: ["Model documentation", "Understanding how models make decisions, crucial for trust and compliance", "Model performance measurement", "Model complexity assessment"], explanation: "Model interpretability helps understand decision-making processes, essential for building trust, debugging, and meeting regulatory requirements." },
                        { q: "How do you handle missing data in machine learning?", a: "Imputation, deletion, or algorithms that handle missing values", options: ["Always delete missing data", "Imputation, deletion, or algorithms that handle missing values", "Replace with zeros", "Missing data is not a problem"], explanation: "Missing data can be handled through various imputation techniques, careful deletion strategies, or using algorithms designed to work with missing values." },
                        { q: "What is feature importance and how do you measure it?", a: "Measures contribution of features, using permutation, SHAP, or model-specific methods", options: ["All features are equally important", "Measures contribution of features, using permutation, SHAP, or model-specific methods", "Feature importance is subjective", "Only applies to tree models"], explanation: "Feature importance quantifies how much each feature contributes to model predictions, measured through techniques like permutation importance, SHAP values, or model-specific methods." },
                        { q: "How do you optimize hyperparameters efficiently?", a: "Grid search, random search, Bayesian optimization, or automated methods", options: ["Trial and error only", "Grid search, random search, Bayesian optimization, or automated methods", "Use default values", "Hyperparameter optimization is unnecessary"], explanation: "Efficient hyperparameter optimization uses systematic approaches like grid search, random search, Bayesian optimization, or automated hyperparameter tuning tools." },
                        { q: "What are the challenges of deploying machine learning models?", a: "Data drift, model decay, scalability, monitoring, and infrastructure requirements", options: ["No challenges exist", "Data drift, model decay, scalability, monitoring, and infrastructure requirements", "Just technical implementation", "Only performance issues"], explanation: "ML deployment faces challenges including data distribution changes, model performance decay, scaling requirements, monitoring needs, and infrastructure complexity." },
                        { q: "How do you handle categorical variables in machine learning?", a: "One-hot encoding, label encoding, target encoding, or embeddings", options: ["Ignore categorical variables", "One-hot encoding, label encoding, target encoding, or embeddings", "Convert to numbers randomly", "Categorical variables cannot be used"], explanation: "Categorical variables require encoding techniques like one-hot encoding for nominal categories, label encoding for ordinal data, or more advanced methods like target encoding." },
                        { q: "What is the difference between online and batch learning?", a: "Online learns incrementally, batch learns from entire dataset at once", options: ["Online is faster", "Online learns incrementally, batch learns from entire dataset at once", "Batch is more accurate", "No practical difference"], explanation: "Online learning updates models incrementally with new data, while batch learning processes the entire dataset at once before updating the model." },
                        { q: "How do you validate time series models?", a: "Time-aware splits, walk-forward validation, avoiding data leakage", options: ["Standard cross-validation", "Time-aware splits, walk-forward validation, avoiding data leakage", "Random sampling", "Validation is not needed"], explanation: "Time series validation requires chronological data splits, walk-forward validation, and careful attention to prevent future data from leaking into past predictions." },
                        { q: "What is active learning?", a: "Strategically selecting most informative samples for labeling", options: ["Learning while active", "Strategically selecting most informative samples for labeling", "Continuous model training", "Interactive learning systems"], explanation: "Active learning strategically queries the most informative unlabeled examples for annotation, maximizing learning efficiency with minimal labeled data." },
                        { q: "How do you handle concept drift?", a: "Monitor performance, retrain models, use adaptive algorithms", options: ["Concept drift is not real", "Monitor performance, retrain models, use adaptive algorithms", "Ignore performance changes", "Use static models only"], explanation: "Concept drift requires continuous monitoring of model performance, periodic retraining, and potentially using adaptive algorithms that can adjust to changing patterns." },
                        { q: "What is multi-label vs multi-class classification?", a: "Multi-label allows multiple true labels, multi-class has one true label", options: ["They're the same thing", "Multi-label allows multiple true labels, multi-class has one true label", "Multi-class is more complex", "Multi-label is binary only"], explanation: "Multi-class classification has one correct class among many options, while multi-label classification can have multiple correct labels simultaneously." }
                    ]
                },
                general: {
                    1: Array.from({length: 17}, (_, i) => ({
                        q: `AI General Basic Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Basic AI concept explanation."
                    })),
                    2: Array.from({length: 17}, (_, i) => ({
                        q: `AI General Medium Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Medium AI concept explanation."
                    })),
                    3: Array.from({length: 16}, (_, i) => ({
                        q: `AI General Hard Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Advanced AI concept explanation."
                    }))
                },
                python_sql: {
                    1: Array.from({length: 17}, (_, i) => ({
                        q: `Python/SQL Basic Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Basic Python/SQL concept explanation."
                    })),
                    2: Array.from({length: 17}, (_, i) => ({
                        q: `Python/SQL Medium Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Medium Python/SQL concept explanation."
                    })),
                    3: Array.from({length: 16}, (_, i) => ({
                        q: `Python/SQL Hard Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Advanced Python/SQL concept explanation."
                    }))
                },
                production: {
                    1: Array.from({length: 17}, (_, i) => ({
                        q: `AI Production Basic Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Basic AI production concept explanation."
                    })),
                    2: Array.from({length: 17}, (_, i) => ({
                        q: `AI Production Medium Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Medium AI production concept explanation."
                    })),
                    3: Array.from({length: 16}, (_, i) => ({
                        q: `AI Production Hard Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Advanced AI production concept explanation."
                    }))
                },
                data_eng: {
                    1: Array.from({length: 17}, (_, i) => ({
                        q: `Data Engineering Basic Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Basic data engineering concept explanation."
                    })),
                    2: Array.from({length: 17}, (_, i) => ({
                        q: `Data Engineering Medium Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Medium data engineering concept explanation."
                    })),
                    3: Array.from({length: 16}, (_, i) => ({
                        q: `Data Engineering Hard Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Advanced data engineering concept explanation."
                    }))
                },
                ethics: {
                    1: Array.from({length: 17}, (_, i) => ({
                        q: `AI Ethics Basic Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Basic AI ethics concept explanation."
                    })),
                    2: Array.from({length: 17}, (_, i) => ({
                        q: `AI Ethics Medium Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Medium AI ethics concept explanation."
                    })),
                    3: Array.from({length: 16}, (_, i) => ({
                        q: `AI Ethics Hard Question ${i+1}`, a: "Answer A", options: ["Answer A", "Answer B", "Answer C", "Answer D"], explanation: "Advanced AI ethics concept explanation."
                    }))
                }
                mlops: {
                    1: [
                        { q: "What does MLOps stand for?", a: "Machine Learning Operations", options: ["Machine Learning Operations", "Machine Learning Optimization", "Multi-Layer Operations", "Model Learning Operations"], explanation: "MLOps combines Machine Learning with Operations, focusing on the deployment, monitoring, and maintenance of ML models in production." },
                        { q: "What is model drift?", a: "Performance degradation over time due to data changes", options: ["Model becoming too complex", "Performance degradation over time due to data changes", "Model taking too long to train", "Model using too much memory"], explanation: "Model drift occurs when a model's performance decreases over time because the real-world data differs from the training data." },
                        { q: "What is the purpose of A/B testing in ML?", a: "Compare performance of different models", options: ["Debug code errors", "Compare performance of different models", "Optimize training speed", "Reduce model size"], explanation: "A/B testing compares the performance of different ML models by splitting traffic and measuring business metrics and model accuracy." },
                        { q: "What is continuous integration in machine learning?", a: "Automated testing and integration of ML code changes", options: ["Manual code reviews", "Automated testing and integration of ML code changes", "Continuous data collection", "Continuous model training"], explanation: "CI in ML involves automated testing of code changes, data validation, model testing, and integration with the ML pipeline." },
                        { q: "What is model versioning?", a: "Tracking different versions of ML models", options: ["Tracking different versions of ML models", "Updating model parameters", "Model performance monitoring", "Model size optimization"], explanation: "Model versioning tracks different iterations of ML models, including their code, data, hyperparameters, and performance metrics." },
                        { q: "What is the purpose of feature stores?", a: "Centralized repository for ML features", options: ["Storing raw data", "Centralized repository for ML features", "Model storage", "Code repository"], explanation: "Feature stores provide a centralized repository for storing, managing, and serving features for ML models, ensuring consistency and reusability." },
                        { q: "What is model monitoring?", a: "Tracking model performance and behavior in production", options: ["Tracking model performance and behavior in production", "Monitoring server resources", "Watching model training", "Code debugging"], explanation: "Model monitoring involves tracking model performance, data quality, prediction accuracy, and system health in production environments." },
                        { q: "What is a model registry?", a: "Centralized repository for storing and managing ML models", options: ["Database for training data", "Centralized repository for storing and managing ML models", "Code version control", "Feature documentation"], explanation: "A model registry is a centralized repository that stores, versions, and manages ML models along with their metadata and lineage information." },
                        { q: "What is the difference between training and inference pipelines?", a: "Training builds models, inference serves predictions", options: ["Training builds models, inference serves predictions", "Training is faster than inference", "Inference requires more data", "No practical difference"], explanation: "Training pipelines build and validate models using historical data, while inference pipelines serve real-time or batch predictions using trained models." },
                        { q: "What is model lineage?", a: "Tracking the origin and evolution of models", options: ["Model family relationships", "Tracking the origin and evolution of models", "Model performance metrics", "Model deployment history"], explanation: "Model lineage tracks the complete history of a model including data sources, transformations, training processes, and deployment information." },
                        { q: "What is automated machine learning (AutoML)?", a: "Automating the ML model development process", options: ["Manual model selection", "Automating the ML model development process", "Automatic data collection", "Self-learning algorithms"], explanation: "AutoML automates various aspects of the ML workflow including feature selection, model selection, hyperparameter tuning, and architecture search." },
                        { q: "What is model reproducibility?", a: "Ability to recreate the same model results", options: ["Model running multiple times", "Ability to recreate the same model results", "Model copying functionality", "Model backup and restore"], explanation: "Model reproducibility ensures that ML experiments can be recreated with the same results by tracking code, data, environment, and random seeds." },
                        { q: "What is the purpose of data validation in ML pipelines?", a: "Ensuring data quality and consistency", options: ["Ensuring data quality and consistency", "Data storage optimization", "Data visualization", "Data encryption"], explanation: "Data validation checks for data quality issues, schema changes, statistical anomalies, and ensures data consistency throughout the ML pipeline." },
                        ]
            }
                        
